Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 52.89it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:09<00:29,  9.99s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:21<00:21, 10.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:30<00:10, 10.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:30<00:00,  6.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:30<00:00,  7.68s/it]
Some weights of the model checkpoint at meta-llama/Llama-3.1-8B were not used when initializing LlamaForSequenceClassification: ['lm_head.weight']
- This IS expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.1-8B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.1-8B and are newly initialized because the shapes did not match:
- model.embed_tokens.weight: found shape torch.Size([128256, 4096]) in the checkpoint and torch.Size([128257, 4096]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['model.layers.16.input_layernorm.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.post_attention_layernorm.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.input_layernorm.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.post_attention_layernorm.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.input_layernorm.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.post_attention_layernorm.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.input_layernorm.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.post_attention_layernorm.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.20.input_layernorm.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.post_attention_layernorm.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.input_layernorm.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.post_attention_layernorm.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.input_layernorm.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.post_attention_layernorm.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.input_layernorm.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.post_attention_layernorm.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.input_layernorm.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.post_attention_layernorm.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.input_layernorm.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.post_attention_layernorm.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.input_layernorm.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.post_attention_layernorm.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.input_layernorm.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.post_attention_layernorm.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.input_layernorm.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.post_attention_layernorm.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.input_layernorm.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.post_attention_layernorm.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.30.input_layernorm.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.post_attention_layernorm.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.input_layernorm.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.post_attention_layernorm.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized because the shapes did not match:
- model.embed_tokens.weight: found shape torch.Size([128256, 2048]) in the checkpoint and torch.Size([128257, 4096]) in the model instantiated
- model.layers.0.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.0.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.0.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.0.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.0.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.0.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.0.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.0.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.0.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.1.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.1.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.1.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.1.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.1.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.1.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.1.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.1.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.1.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.10.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.10.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.10.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.10.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.10.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.10.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.10.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.10.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.10.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.11.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.11.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.11.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.11.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.11.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.11.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.11.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.11.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.11.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.12.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.12.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.12.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.12.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.12.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.12.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.12.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.12.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.12.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.13.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.13.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.13.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.13.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.13.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.13.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.13.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.13.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.13.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.14.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.14.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.14.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.14.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.14.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.14.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.14.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.14.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.14.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.15.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.15.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.15.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.15.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.15.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.15.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.15.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.15.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.15.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.2.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.2.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.2.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.2.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.2.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.2.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.2.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.2.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.2.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.3.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.3.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.3.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.3.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.3.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.3.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.3.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.3.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.3.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.4.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.4.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.4.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.4.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.4.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.4.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.4.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.4.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.4.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.5.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.5.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.5.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.5.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.5.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.5.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.5.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.5.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.5.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.6.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.6.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.6.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.6.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.6.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.6.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.6.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.6.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.6.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.7.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.7.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.7.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.7.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.7.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.7.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.7.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.7.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.7.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.8.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.8.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.8.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.8.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.8.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.8.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.8.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.8.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.8.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.9.input_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.9.mlp.down_proj.weight: found shape torch.Size([2048, 8192]) in the checkpoint and torch.Size([4096, 14336]) in the model instantiated
- model.layers.9.mlp.gate_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.9.mlp.up_proj.weight: found shape torch.Size([8192, 2048]) in the checkpoint and torch.Size([14336, 4096]) in the model instantiated
- model.layers.9.post_attention_layernorm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
- model.layers.9.self_attn.k_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.layers.9.self_attn.o_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.9.self_attn.q_proj.weight: found shape torch.Size([2048, 2048]) in the checkpoint and torch.Size([4096, 4096]) in the model instantiated
- model.layers.9.self_attn.v_proj.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1024, 4096]) in the model instantiated
- model.norm.weight: found shape torch.Size([2048]) in the checkpoint and torch.Size([4096]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/NFSHOME/gdaloisio/code/CodeXGLUE/Code-Code/Defect-detection/code/llama_distillation.py:87: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  loss =  F.kl_div(F.log_softmax(student_logits/10.00), F.softmax(teacher_logits / 10.00), reduction="batchmean") * (10**2)
/NFSHOME/gdaloisio/code/CodeXGLUE/Code-Code/Defect-detection/code/llama_distillation.py:87: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  loss =  F.kl_div(F.log_softmax(student_logits/10.00), F.softmax(teacher_logits / 10.00), reduction="batchmean") * (10**2)
{'idx': tensor([ 8, 10, 15, 22, 51, 62, 71, 75]), 'input_ids': tensor([[128000,   2020,    742,  ..., 128256, 128256, 128256],
        [128000,   2020,   7533,  ..., 128256, 128256, 128256],
        [128000,   1019,  34986,  ..., 128256, 128256, 128256],
        ...,
        [128000,   2020,    742,  ...,   1026,     72,     11],
        [128000,   1019,  77053,  ..., 128256, 128256, 128256],
        [128000,   2020,    742,  ...,   1390,    311,  17460]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 1, 1, 1, 0, 0, 0, 0])}
Traceback (most recent call last):
  File "/NFSHOME/gdaloisio/code/CodeXGLUE/Code-Code/Defect-detection/code/llama_distillation.py", line 105, in <module>
    main(args)
    ~~~~^^^^^^
  File "/NFSHOME/gdaloisio/code/CodeXGLUE/Code-Code/Defect-detection/code/llama_distillation.py", line 84, in main
    student_outputs = student_model(input_ids=input_ids, attention_mask=attention_mask)
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/transformers/utils/generic.py", line 969, in wrapper
    output = func(self, *args, **kwargs)
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py", line 770, in forward
    transformer_outputs: BaseModelOutputWithPast = self.model(
                                                   ~~~~~~~~~~^
        input_ids,
        ^^^^^^^^^^
    ...<6 lines>...
        output_hidden_states=output_hidden_states,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/transformers/utils/generic.py", line 969, in wrapper
    output = func(self, *args, **kwargs)
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py", line 453, in forward
    layer_outputs = decoder_layer(
        hidden_states,
    ...<7 lines>...
        **flash_attn_kwargs,
    )
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/transformers/modeling_layers.py", line 48, in __call__
    return super().__call__(*args, **kwargs)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py", line 323, in forward
    hidden_states = self.post_attention_layernorm(hidden_states)
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py", line 73, in forward
    return self.weight * hidden_states.to(input_dtype)
                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 8.56 MiB is free. Including non-PyTorch memory, this process has 79.12 GiB memory in use. Of the allocated memory 78.75 GiB is allocated by PyTorch, and 85.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
srun: error: compute-2-3: task 0: Exited with exit code 1
