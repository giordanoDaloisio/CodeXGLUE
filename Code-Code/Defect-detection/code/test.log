03/25/2025 11:50:49 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 1, distributed training: False, 16-bits training: False
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
03/25/2025 11:50:54 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../dataset/train.jsonl', output_dir='./saved_models_graph', eval_data_file='../dataset/valid.jsonl', test_data_file='../dataset/test.jsonl', model_type='roberta', model_name_or_path='microsoft/graphcodebert-base', model=None, mlm=False, mlm_probability=0.15, config_name='', tokenizer_name='microsoft/graphcodebert-base', cache_dir='', block_size=400, do_train=False, do_eval=True, do_test=True, evaluate_during_training=True, do_lower_case=False, train_batch_size=32, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=True, overwrite_output_dir=False, overwrite_cache=False, seed=123456, epoch=5, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', early_stopping_patience=None, min_loss_delta=0.001, dropout_probability=0, job_id='487100', quantize_dynamic=False, quantize_static=False, quantize=False, quantize4=False, quantizef8=False, prune_local=False, prune6=False, prune4=True, prune=False, attention_heads=None, hidden_dim=None, intermediate_size=None, n_layers=None, vocab_size=None, n_gpu=1, per_gpu_train_batch_size=32, per_gpu_eval_batch_size=64, device=device(type='cpu'), start_epoch=0, start_step=0)
03/25/2025 11:50:56 - INFO - __main__ -   ******* Apply Pruning 0.4 ***********
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:50:58 - INFO - __main__ -   True
03/25/2025 11:50:58 - INFO - __main__ -   False
03/25/2025 11:51:00 - INFO - __main__ -   Size (MB): 498.655532
==========================================================================================
Layer (type:depth-idx)                                            Param #
==========================================================================================
Model                                                             --
├─RobertaForSequenceClassification: 1-1                           --
│    └─roberta.embeddings.word_embeddings.weight                  ├─38,603,520
│    └─roberta.embeddings.position_embeddings.weight              ├─394,752
│    └─roberta.embeddings.token_type_embeddings.weight            ├─768
│    └─roberta.embeddings.LayerNorm.weight                        ├─768
│    └─roberta.embeddings.LayerNorm.bias                          ├─768
│    └─roberta.encoder.layer.0.attention.self.query.bias          ├─768
│    └─roberta.encoder.layer.0.attention.self.query.weight        ├─589,824
│    └─roberta.encoder.layer.0.attention.self.key.bias            ├─768
│    └─roberta.encoder.layer.0.attention.self.key.weight          ├─589,824
│    └─roberta.encoder.layer.0.attention.self.value.bias          ├─768
│    └─roberta.encoder.layer.0.attention.self.value.weight        ├─589,824
│    └─roberta.encoder.layer.0.attention.output.dense.weight      ├─589,824
│    └─roberta.encoder.layer.0.attention.output.dense.bias        ├─768
│    └─roberta.encoder.layer.0.attention.output.LayerNorm.weight  ├─768
│    └─roberta.encoder.layer.0.attention.output.LayerNorm.bias    ├─768
│    └─roberta.encoder.layer.0.intermediate.dense.weight          ├─2,359,296
│    └─roberta.encoder.layer.0.intermediate.dense.bias            ├─3,072
│    └─roberta.encoder.layer.0.output.dense.weight                ├─2,359,296
│    └─roberta.encoder.layer.0.output.dense.bias                  ├─768
│    └─roberta.encoder.layer.0.output.LayerNorm.weight            ├─768
│    └─roberta.encoder.layer.0.output.LayerNorm.bias              ├─768
│    └─roberta.encoder.layer.1.attention.self.query.bias          ├─768
│    └─roberta.encoder.layer.1.attention.self.query.weight        ├─589,824
│    └─roberta.encoder.layer.1.attention.self.key.bias            ├─768
│    └─roberta.encoder.layer.1.attention.self.key.weight          ├─589,824
│    └─roberta.encoder.layer.1.attention.self.value.bias          ├─768
│    └─roberta.encoder.layer.1.attention.self.value.weight        ├─589,824
│    └─roberta.encoder.layer.1.attention.output.dense.weight      ├─589,824
│    └─roberta.encoder.layer.1.attention.output.dense.bias        ├─768
│    └─roberta.encoder.layer.1.attention.output.LayerNorm.weight  ├─768
│    └─roberta.encoder.layer.1.attention.output.LayerNorm.bias    ├─768
│    └─roberta.encoder.layer.1.intermediate.dense.weight          ├─2,359,296
│    └─roberta.encoder.layer.1.intermediate.dense.bias            ├─3,072
│    └─roberta.encoder.layer.1.output.dense.weight                ├─2,359,296
│    └─roberta.encoder.layer.1.output.dense.bias                  ├─768
│    └─roberta.encoder.layer.1.output.LayerNorm.weight            ├─768
│    └─roberta.encoder.layer.1.output.LayerNorm.bias              ├─768
│    └─roberta.encoder.layer.2.attention.self.query.bias          ├─768
│    └─roberta.encoder.layer.2.attention.self.query.weight        ├─589,824
│    └─roberta.encoder.layer.2.attention.self.key.bias            ├─768
│    └─roberta.encoder.layer.2.attention.self.key.weight          ├─589,824
│    └─roberta.encoder.layer.2.attention.self.value.bias          ├─768
│    └─roberta.encoder.layer.2.attention.self.value.weight        ├─589,824
│    └─roberta.encoder.layer.2.attention.output.dense.weight      ├─589,824
│    └─roberta.encoder.layer.2.attention.output.dense.bias        ├─768
│    └─roberta.encoder.layer.2.attention.output.LayerNorm.weight  ├─768
│    └─roberta.encoder.layer.2.attention.output.LayerNorm.bias    ├─768
│    └─roberta.encoder.layer.2.intermediate.dense.weight          ├─2,359,296
│    └─roberta.encoder.layer.2.intermediate.dense.bias            ├─3,072
│    └─roberta.encoder.layer.2.output.dense.weight                ├─2,359,296
│    └─roberta.encoder.layer.2.output.dense.bias                  ├─768
│    └─roberta.encoder.layer.2.output.LayerNorm.weight            ├─768
│    └─roberta.encoder.layer.2.output.LayerNorm.bias              ├─768
│    └─roberta.encoder.layer.3.attention.self.query.bias          ├─768
│    └─roberta.encoder.layer.3.attention.self.query.weight        ├─589,824
│    └─roberta.encoder.layer.3.attention.self.key.bias            ├─768
│    └─roberta.encoder.layer.3.attention.self.key.weight          ├─589,824
│    └─roberta.encoder.layer.3.attention.self.value.bias          ├─768
│    └─roberta.encoder.layer.3.attention.self.value.weight        ├─589,824
│    └─roberta.encoder.layer.3.attention.output.dense.weight      ├─589,824
│    └─roberta.encoder.layer.3.attention.output.dense.bias        ├─768
│    └─roberta.encoder.layer.3.attention.output.LayerNorm.weight  ├─768
│    └─roberta.encoder.layer.3.attention.output.LayerNorm.bias    ├─768
│    └─roberta.encoder.layer.3.intermediate.dense.weight          ├─2,359,296
│    └─roberta.encoder.layer.3.intermediate.dense.bias            ├─3,072
│    └─roberta.encoder.layer.3.output.dense.weight                ├─2,359,296
│    └─roberta.encoder.layer.3.output.dense.bias                  ├─768
│    └─roberta.encoder.layer.3.output.LayerNorm.weight            ├─768
│    └─roberta.encoder.layer.3.output.LayerNorm.bias              ├─768
│    └─roberta.encoder.layer.4.attention.self.query.bias          ├─768
│    └─roberta.encoder.layer.4.attention.self.query.weight        ├─589,824
│    └─roberta.encoder.layer.4.attention.self.key.bias            ├─768
│    └─roberta.encoder.layer.4.attention.self.key.weight          ├─589,824
│    └─roberta.encoder.layer.4.attention.self.value.bias          ├─768
│    └─roberta.encoder.layer.4.attention.self.value.weight        ├─589,824
│    └─roberta.encoder.layer.4.attention.output.dense.weight      ├─589,824
│    └─roberta.encoder.layer.4.attention.output.dense.bias        ├─768
│    └─roberta.encoder.layer.4.attention.output.LayerNorm.weight  ├─768
│    └─roberta.encoder.layer.4.attention.output.LayerNorm.bias    ├─768
│    └─roberta.encoder.layer.4.intermediate.dense.weight          ├─2,359,296
│    └─roberta.encoder.layer.4.intermediate.dense.bias            ├─3,072
│    └─roberta.encoder.layer.4.output.dense.weight                ├─2,359,296
│    └─roberta.encoder.layer.4.output.dense.bias                  ├─768
│    └─roberta.encoder.layer.4.output.LayerNorm.weight            ├─768
│    └─roberta.encoder.layer.4.output.LayerNorm.bias              ├─768
│    └─roberta.encoder.layer.5.attention.self.query.bias          ├─768
│    └─roberta.encoder.layer.5.attention.self.query.weight        ├─589,824
│    └─roberta.encoder.layer.5.attention.self.key.bias            ├─768
│    └─roberta.encoder.layer.5.attention.self.key.weight          ├─589,824
│    └─roberta.encoder.layer.5.attention.self.value.bias          ├─768
│    └─roberta.encoder.layer.5.attention.self.value.weight        ├─589,824
│    └─roberta.encoder.layer.5.attention.output.dense.weight      ├─589,824
│    └─roberta.encoder.layer.5.attention.output.dense.bias        ├─768
│    └─roberta.encoder.layer.5.attention.output.LayerNorm.weight  ├─768
│    └─roberta.encoder.layer.5.attention.output.LayerNorm.bias    ├─768
│    └─roberta.encoder.layer.5.intermediate.dense.weight          ├─2,359,296
│    └─roberta.encoder.layer.5.intermediate.dense.bias            ├─3,072
│    └─roberta.encoder.layer.5.output.dense.weight                ├─2,359,296
│    └─roberta.encoder.layer.5.output.dense.bias                  ├─768
│    └─roberta.encoder.layer.5.output.LayerNorm.weight            ├─768
│    └─roberta.encoder.layer.5.output.LayerNorm.bias              ├─768
│    └─roberta.encoder.layer.6.attention.self.query.bias          ├─768
│    └─roberta.encoder.layer.6.attention.self.query.weight        ├─589,824
│    └─roberta.encoder.layer.6.attention.self.key.bias            ├─768
│    └─roberta.encoder.layer.6.attention.self.key.weight          ├─589,824
│    └─roberta.encoder.layer.6.attention.self.value.bias          ├─768
│    └─roberta.encoder.layer.6.attention.self.value.weight        ├─589,824
│    └─roberta.encoder.layer.6.attention.output.dense.weight      ├─589,824
│    └─roberta.encoder.layer.6.attention.output.dense.bias        ├─768
│    └─roberta.encoder.layer.6.attention.output.LayerNorm.weight  ├─768
│    └─roberta.encoder.layer.6.attention.output.LayerNorm.bias    ├─768
│    └─roberta.encoder.layer.6.intermediate.dense.weight          ├─2,359,296
│    └─roberta.encoder.layer.6.intermediate.dense.bias            ├─3,072
│    └─roberta.encoder.layer.6.output.dense.weight                ├─2,359,296
│    └─roberta.encoder.layer.6.output.dense.bias                  ├─768
│    └─roberta.encoder.layer.6.output.LayerNorm.weight            ├─768
│    └─roberta.encoder.layer.6.output.LayerNorm.bias              ├─768
│    └─roberta.encoder.layer.7.attention.self.query.bias          ├─768
│    └─roberta.encoder.layer.7.attention.self.query.weight        ├─589,824
│    └─roberta.encoder.layer.7.attention.self.key.bias            ├─768
│    └─roberta.encoder.layer.7.attention.self.key.weight          ├─589,824
│    └─roberta.encoder.layer.7.attention.self.value.bias          ├─768
│    └─roberta.encoder.layer.7.attention.self.value.weight        ├─589,824
│    └─roberta.encoder.layer.7.attention.output.dense.weight      ├─589,824
│    └─roberta.encoder.layer.7.attention.output.dense.bias        ├─768
│    └─roberta.encoder.layer.7.attention.output.LayerNorm.weight  ├─768
│    └─roberta.encoder.layer.7.attention.output.LayerNorm.bias    ├─768
│    └─roberta.encoder.layer.7.intermediate.dense.weight          ├─2,359,296
│    └─roberta.encoder.layer.7.intermediate.dense.bias            ├─3,072
│    └─roberta.encoder.layer.7.output.dense.weight                ├─2,359,296
│    └─roberta.encoder.layer.7.output.dense.bias                  ├─768
│    └─roberta.encoder.layer.7.output.LayerNorm.weight            ├─768
│    └─roberta.encoder.layer.7.output.LayerNorm.bias              ├─768
│    └─roberta.encoder.layer.8.attention.self.query.bias          ├─768
│    └─roberta.encoder.layer.8.attention.self.query.weight        ├─589,824
│    └─roberta.encoder.layer.8.attention.self.key.bias            ├─768
│    └─roberta.encoder.layer.8.attention.self.key.weight          ├─589,824
│    └─roberta.encoder.layer.8.attention.self.value.bias          ├─768
│    └─roberta.encoder.layer.8.attention.self.value.weight        ├─589,824
│    └─roberta.encoder.layer.8.attention.output.dense.weight      ├─589,824
│    └─roberta.encoder.layer.8.attention.output.dense.bias        ├─768
│    └─roberta.encoder.layer.8.attention.output.LayerNorm.weight  ├─768
│    └─roberta.encoder.layer.8.attention.output.LayerNorm.bias    ├─768
│    └─roberta.encoder.layer.8.intermediate.dense.weight          ├─2,359,296
│    └─roberta.encoder.layer.8.intermediate.dense.bias            ├─3,072
│    └─roberta.encoder.layer.8.output.dense.weight                ├─2,359,296
│    └─roberta.encoder.layer.8.output.dense.bias                  ├─768
│    └─roberta.encoder.layer.8.output.LayerNorm.weight            ├─768
│    └─roberta.encoder.layer.8.output.LayerNorm.bias              ├─768
│    └─roberta.encoder.layer.9.attention.self.query.bias          ├─768
│    └─roberta.encoder.layer.9.attention.self.query.weight        ├─589,824
│    └─roberta.encoder.layer.9.attention.self.key.bias            ├─768
│    └─roberta.encoder.layer.9.attention.self.key.weight          ├─589,824
│    └─roberta.encoder.layer.9.attention.self.value.bias          ├─768
│    └─roberta.encoder.layer.9.attention.self.value.weight        ├─589,824
│    └─roberta.encoder.layer.9.attention.output.dense.weight      ├─589,824
│    └─roberta.encoder.layer.9.attention.output.dense.bias        ├─768
│    └─roberta.encoder.layer.9.attention.output.LayerNorm.weight  ├─768
│    └─roberta.encoder.layer.9.attention.output.LayerNorm.bias    ├─768
│    └─roberta.encoder.layer.9.intermediate.dense.weight          ├─2,359,296
│    └─roberta.encoder.layer.9.intermediate.dense.bias            ├─3,072
│    └─roberta.encoder.layer.9.output.dense.weight                ├─2,359,296
│    └─roberta.encoder.layer.9.output.dense.bias                  ├─768
│    └─roberta.encoder.layer.9.output.LayerNorm.weight            ├─768
│    └─roberta.encoder.layer.9.output.LayerNorm.bias              ├─768
│    └─roberta.encoder.layer.10.attention.self.query.bias         ├─768
│    └─roberta.encoder.layer.10.attention.self.query.weight       ├─589,824
│    └─roberta.encoder.layer.10.attention.self.key.bias           ├─768
│    └─roberta.encoder.layer.10.attention.self.key.weight         ├─589,824
│    └─roberta.encoder.layer.10.attention.self.value.bias         ├─768
│    └─roberta.encoder.layer.10.attention.self.value.weight       ├─589,824
│    └─roberta.encoder.layer.10.attention.output.dense.weight     ├─589,824
│    └─roberta.encoder.layer.10.attention.output.dense.bias       ├─768
│    └─roberta.encoder.layer.10.attention.output.LayerNorm.weight ├─768
│    └─roberta.encoder.layer.10.attention.output.LayerNorm.bias   ├─768
│    └─roberta.encoder.layer.10.intermediate.dense.weight         ├─2,359,296
│    └─roberta.encoder.layer.10.intermediate.dense.bias           ├─3,072
│    └─roberta.encoder.layer.10.output.dense.weight               ├─2,359,296
│    └─roberta.encoder.layer.10.output.dense.bias                 ├─768
│    └─roberta.encoder.layer.10.output.LayerNorm.weight           ├─768
│    └─roberta.encoder.layer.10.output.LayerNorm.bias             ├─768
│    └─roberta.encoder.layer.11.attention.self.query.bias         ├─768
│    └─roberta.encoder.layer.11.attention.self.query.weight       ├─589,824
│    └─roberta.encoder.layer.11.attention.self.key.bias           ├─768
│    └─roberta.encoder.layer.11.attention.self.key.weight         ├─589,824
│    └─roberta.encoder.layer.11.attention.self.value.bias         ├─768
│    └─roberta.encoder.layer.11.attention.self.value.weight       ├─589,824
│    └─roberta.encoder.layer.11.attention.output.dense.weight     ├─589,824
│    └─roberta.encoder.layer.11.attention.output.dense.bias       ├─768
│    └─roberta.encoder.layer.11.attention.output.LayerNorm.weight ├─768
│    └─roberta.encoder.layer.11.attention.output.LayerNorm.bias   ├─768
│    └─roberta.encoder.layer.11.intermediate.dense.weight         ├─2,359,296
│    └─roberta.encoder.layer.11.intermediate.dense.bias           ├─3,072
│    └─roberta.encoder.layer.11.output.dense.weight               ├─2,359,296
│    └─roberta.encoder.layer.11.output.dense.bias                 ├─768
│    └─roberta.encoder.layer.11.output.LayerNorm.weight           ├─768
│    └─roberta.encoder.layer.11.output.LayerNorm.bias             ├─768
│    └─classifier.dense.weight                                    ├─589,824
│    └─classifier.dense.bias                                      ├─768
│    └─classifier.out_proj.weight                                 ├─768
│    └─classifier.out_proj.bias                                   └─1
│    └─RobertaModel: 2-1                                          --
│    │    └─embeddings.word_embeddings.weight                     ├─38,603,520
│    │    └─embeddings.position_embeddings.weight                 ├─394,752
│    │    └─embeddings.token_type_embeddings.weight               ├─768
│    │    └─embeddings.LayerNorm.weight                           ├─768
│    │    └─embeddings.LayerNorm.bias                             ├─768
│    │    └─encoder.layer.0.attention.self.query.bias             ├─768
│    │    └─encoder.layer.0.attention.self.query.weight           ├─589,824
│    │    └─encoder.layer.0.attention.self.key.bias               ├─768
│    │    └─encoder.layer.0.attention.self.key.weight             ├─589,824
│    │    └─encoder.layer.0.attention.self.value.bias             ├─768
│    │    └─encoder.layer.0.attention.self.value.weight           ├─589,824
│    │    └─encoder.layer.0.attention.output.dense.weight         ├─589,824
│    │    └─encoder.layer.0.attention.output.dense.bias           ├─768
│    │    └─encoder.layer.0.attention.output.LayerNorm.weight     ├─768
│    │    └─encoder.layer.0.attention.output.LayerNorm.bias       ├─768
│    │    └─encoder.layer.0.intermediate.dense.weight             ├─2,359,296
│    │    └─encoder.layer.0.intermediate.dense.bias               ├─3,072
│    │    └─encoder.layer.0.output.dense.weight                   ├─2,359,296
│    │    └─encoder.layer.0.output.dense.bias                     ├─768
│    │    └─encoder.layer.0.output.LayerNorm.weight               ├─768
│    │    └─encoder.layer.0.output.LayerNorm.bias                 ├─768
│    │    └─encoder.layer.1.attention.self.query.bias             ├─768
│    │    └─encoder.layer.1.attention.self.query.weight           ├─589,824
│    │    └─encoder.layer.1.attention.self.key.bias               ├─768
│    │    └─encoder.layer.1.attention.self.key.weight             ├─589,824
│    │    └─encoder.layer.1.attention.self.value.bias             ├─768
│    │    └─encoder.layer.1.attention.self.value.weight           ├─589,824
│    │    └─encoder.layer.1.attention.output.dense.weight         ├─589,824
│    │    └─encoder.layer.1.attention.output.dense.bias           ├─768
│    │    └─encoder.layer.1.attention.output.LayerNorm.weight     ├─768
│    │    └─encoder.layer.1.attention.output.LayerNorm.bias       ├─768
│    │    └─encoder.layer.1.intermediate.dense.weight             ├─2,359,296
│    │    └─encoder.layer.1.intermediate.dense.bias               ├─3,072
│    │    └─encoder.layer.1.output.dense.weight                   ├─2,359,296
│    │    └─encoder.layer.1.output.dense.bias                     ├─768
│    │    └─encoder.layer.1.output.LayerNorm.weight               ├─768
│    │    └─encoder.layer.1.output.LayerNorm.bias                 ├─768
│    │    └─encoder.layer.2.attention.self.query.bias             ├─768
│    │    └─encoder.layer.2.attention.self.query.weight           ├─589,824
│    │    └─encoder.layer.2.attention.self.key.bias               ├─768
│    │    └─encoder.layer.2.attention.self.key.weight             ├─589,824
│    │    └─encoder.layer.2.attention.self.value.bias             ├─768
│    │    └─encoder.layer.2.attention.self.value.weight           ├─589,824
│    │    └─encoder.layer.2.attention.output.dense.weight         ├─589,824
│    │    └─encoder.layer.2.attention.output.dense.bias           ├─768
│    │    └─encoder.layer.2.attention.output.LayerNorm.weight     ├─768
│    │    └─encoder.layer.2.attention.output.LayerNorm.bias       ├─768
│    │    └─encoder.layer.2.intermediate.dense.weight             ├─2,359,296
│    │    └─encoder.layer.2.intermediate.dense.bias               ├─3,072
│    │    └─encoder.layer.2.output.dense.weight                   ├─2,359,296
│    │    └─encoder.layer.2.output.dense.bias                     ├─768
│    │    └─encoder.layer.2.output.LayerNorm.weight               ├─768
│    │    └─encoder.layer.2.output.LayerNorm.bias                 ├─768
│    │    └─encoder.layer.3.attention.self.query.bias             ├─768
│    │    └─encoder.layer.3.attention.self.query.weight           ├─589,824
│    │    └─encoder.layer.3.attention.self.key.bias               ├─768
│    │    └─encoder.layer.3.attention.self.key.weight             ├─589,824
│    │    └─encoder.layer.3.attention.self.value.bias             ├─768
│    │    └─encoder.layer.3.attention.self.value.weight           ├─589,824
│    │    └─encoder.layer.3.attention.output.dense.weight         ├─589,824
│    │    └─encoder.layer.3.attention.output.dense.bias           ├─768
│    │    └─encoder.layer.3.attention.output.LayerNorm.weight     ├─768
│    │    └─encoder.layer.3.attention.output.LayerNorm.bias       ├─768
│    │    └─encoder.layer.3.intermediate.dense.weight             ├─2,359,296
│    │    └─encoder.layer.3.intermediate.dense.bias               ├─3,072
│    │    └─encoder.layer.3.output.dense.weight                   ├─2,359,296
│    │    └─encoder.layer.3.output.dense.bias                     ├─768
│    │    └─encoder.layer.3.output.LayerNorm.weight               ├─768
│    │    └─encoder.layer.3.output.LayerNorm.bias                 ├─768
│    │    └─encoder.layer.4.attention.self.query.bias             ├─768
│    │    └─encoder.layer.4.attention.self.query.weight           ├─589,824
│    │    └─encoder.layer.4.attention.self.key.bias               ├─768
│    │    └─encoder.layer.4.attention.self.key.weight             ├─589,824
│    │    └─encoder.layer.4.attention.self.value.bias             ├─768
│    │    └─encoder.layer.4.attention.self.value.weight           ├─589,824
│    │    └─encoder.layer.4.attention.output.dense.weight         ├─589,824
│    │    └─encoder.layer.4.attention.output.dense.bias           ├─768
│    │    └─encoder.layer.4.attention.output.LayerNorm.weight     ├─768
│    │    └─encoder.layer.4.attention.output.LayerNorm.bias       ├─768
│    │    └─encoder.layer.4.intermediate.dense.weight             ├─2,359,296
│    │    └─encoder.layer.4.intermediate.dense.bias               ├─3,072
│    │    └─encoder.layer.4.output.dense.weight                   ├─2,359,296
│    │    └─encoder.layer.4.output.dense.bias                     ├─768
│    │    └─encoder.layer.4.output.LayerNorm.weight               ├─768
│    │    └─encoder.layer.4.output.LayerNorm.bias                 ├─768
│    │    └─encoder.layer.5.attention.self.query.bias             ├─768
│    │    └─encoder.layer.5.attention.self.query.weight           ├─589,824
│    │    └─encoder.layer.5.attention.self.key.bias               ├─768
│    │    └─encoder.layer.5.attention.self.key.weight             ├─589,824
│    │    └─encoder.layer.5.attention.self.value.bias             ├─768
│    │    └─encoder.layer.5.attention.self.value.weight           ├─589,824
│    │    └─encoder.layer.5.attention.output.dense.weight         ├─589,824
│    │    └─encoder.layer.5.attention.output.dense.bias           ├─768
│    │    └─encoder.layer.5.attention.output.LayerNorm.weight     ├─768
│    │    └─encoder.layer.5.attention.output.LayerNorm.bias       ├─768
│    │    └─encoder.layer.5.intermediate.dense.weight             ├─2,359,296
│    │    └─encoder.layer.5.intermediate.dense.bias               ├─3,072
│    │    └─encoder.layer.5.output.dense.weight                   ├─2,359,296
│    │    └─encoder.layer.5.output.dense.bias                     ├─768
│    │    └─encoder.layer.5.output.LayerNorm.weight               ├─768
│    │    └─encoder.layer.5.output.LayerNorm.bias                 ├─768
│    │    └─encoder.layer.6.attention.self.query.bias             ├─768
│    │    └─encoder.layer.6.attention.self.query.weight           ├─589,824
│    │    └─encoder.layer.6.attention.self.key.bias               ├─768
│    │    └─encoder.layer.6.attention.self.key.weight             ├─589,824
│    │    └─encoder.layer.6.attention.self.value.bias             ├─768
│    │    └─encoder.layer.6.attention.self.value.weight           ├─589,824
│    │    └─encoder.layer.6.attention.output.dense.weight         ├─589,824
│    │    └─encoder.layer.6.attention.output.dense.bias           ├─768
│    │    └─encoder.layer.6.attention.output.LayerNorm.weight     ├─768
│    │    └─encoder.layer.6.attention.output.LayerNorm.bias       ├─768
│    │    └─encoder.layer.6.intermediate.dense.weight             ├─2,359,296
│    │    └─encoder.layer.6.intermediate.dense.bias               ├─3,072
│    │    └─encoder.layer.6.output.dense.weight                   ├─2,359,296
│    │    └─encoder.layer.6.output.dense.bias                     ├─768
│    │    └─encoder.layer.6.output.LayerNorm.weight               ├─768
│    │    └─encoder.layer.6.output.LayerNorm.bias                 ├─768
│    │    └─encoder.layer.7.attention.self.query.bias             ├─768
│    │    └─encoder.layer.7.attention.self.query.weight           ├─589,824
│    │    └─encoder.layer.7.attention.self.key.bias               ├─768
│    │    └─encoder.layer.7.attention.self.key.weight             ├─589,824
│    │    └─encoder.layer.7.attention.self.value.bias             ├─768
│    │    └─encoder.layer.7.attention.self.value.weight           ├─589,824
│    │    └─encoder.layer.7.attention.output.dense.weight         ├─589,824
│    │    └─encoder.layer.7.attention.output.dense.bias           ├─768
│    │    └─encoder.layer.7.attention.output.LayerNorm.weight     ├─768
│    │    └─encoder.layer.7.attention.output.LayerNorm.bias       ├─768
│    │    └─encoder.layer.7.intermediate.dense.weight             ├─2,359,296
│    │    └─encoder.layer.7.intermediate.dense.bias               ├─3,072
│    │    └─encoder.layer.7.output.dense.weight                   ├─2,359,296
│    │    └─encoder.layer.7.output.dense.bias                     ├─768
│    │    └─encoder.layer.7.output.LayerNorm.weight               ├─768
│    │    └─encoder.layer.7.output.LayerNorm.bias                 ├─768
│    │    └─encoder.layer.8.attention.self.query.bias             ├─768
│    │    └─encoder.layer.8.attention.self.query.weight           ├─589,824
│    │    └─encoder.layer.8.attention.self.key.bias               ├─768
│    │    └─encoder.layer.8.attention.self.key.weight             ├─589,824
│    │    └─encoder.layer.8.attention.self.value.bias             ├─768
│    │    └─encoder.layer.8.attention.self.value.weight           ├─589,824
│    │    └─encoder.layer.8.attention.output.dense.weight         ├─589,824
│    │    └─encoder.layer.8.attention.output.dense.bias           ├─768
│    │    └─encoder.layer.8.attention.output.LayerNorm.weight     ├─768
│    │    └─encoder.layer.8.attention.output.LayerNorm.bias       ├─768
│    │    └─encoder.layer.8.intermediate.dense.weight             ├─2,359,296
│    │    └─encoder.layer.8.intermediate.dense.bias               ├─3,072
│    │    └─encoder.layer.8.output.dense.weight                   ├─2,359,296
│    │    └─encoder.layer.8.output.dense.bias                     ├─768
│    │    └─encoder.layer.8.output.LayerNorm.weight               ├─768
│    │    └─encoder.layer.8.output.LayerNorm.bias                 ├─768
│    │    └─encoder.layer.9.attention.self.query.bias             ├─768
│    │    └─encoder.layer.9.attention.self.query.weight           ├─589,824
│    │    └─encoder.layer.9.attention.self.key.bias               ├─768
│    │    └─encoder.layer.9.attention.self.key.weight             ├─589,824
│    │    └─encoder.layer.9.attention.self.value.bias             ├─768
│    │    └─encoder.layer.9.attention.self.value.weight           ├─589,824
│    │    └─encoder.layer.9.attention.output.dense.weight         ├─589,824
│    │    └─encoder.layer.9.attention.output.dense.bias           ├─768
│    │    └─encoder.layer.9.attention.output.LayerNorm.weight     ├─768
│    │    └─encoder.layer.9.attention.output.LayerNorm.bias       ├─768
│    │    └─encoder.layer.9.intermediate.dense.weight             ├─2,359,296
│    │    └─encoder.layer.9.intermediate.dense.bias               ├─3,072
│    │    └─encoder.layer.9.output.dense.weight                   ├─2,359,296
│    │    └─encoder.layer.9.output.dense.bias                     ├─768
│    │    └─encoder.layer.9.output.LayerNorm.weight               ├─768
│    │    └─encoder.layer.9.output.LayerNorm.bias                 ├─768
│    │    └─encoder.layer.10.attention.self.query.bias            ├─768
│    │    └─encoder.layer.10.attention.self.query.weight          ├─589,824
│    │    └─encoder.layer.10.attention.self.key.bias              ├─768
│    │    └─encoder.layer.10.attention.self.key.weight            ├─589,824
│    │    └─encoder.layer.10.attention.self.value.bias            ├─768
│    │    └─encoder.layer.10.attention.self.value.weight          ├─589,824
│    │    └─encoder.layer.10.attention.output.dense.weight        ├─589,824
│    │    └─encoder.layer.10.attention.output.dense.bias          ├─768
│    │    └─encoder.layer.10.attention.output.LayerNorm.weight    ├─768
│    │    └─encoder.layer.10.attention.output.LayerNorm.bias      ├─768
│    │    └─encoder.layer.10.intermediate.dense.weight            ├─2,359,296
│    │    └─encoder.layer.10.intermediate.dense.bias              ├─3,072
│    │    └─encoder.layer.10.output.dense.weight                  ├─2,359,296
│    │    └─encoder.layer.10.output.dense.bias                    ├─768
│    │    └─encoder.layer.10.output.LayerNorm.weight              ├─768
│    │    └─encoder.layer.10.output.LayerNorm.bias                ├─768
│    │    └─encoder.layer.11.attention.self.query.bias            ├─768
│    │    └─encoder.layer.11.attention.self.query.weight          ├─589,824
│    │    └─encoder.layer.11.attention.self.key.bias              ├─768
│    │    └─encoder.layer.11.attention.self.key.weight            ├─589,824
│    │    └─encoder.layer.11.attention.self.value.bias            ├─768
│    │    └─encoder.layer.11.attention.self.value.weight          ├─589,824
│    │    └─encoder.layer.11.attention.output.dense.weight        ├─589,824
│    │    └─encoder.layer.11.attention.output.dense.bias          ├─768
│    │    └─encoder.layer.11.attention.output.LayerNorm.weight    ├─768
│    │    └─encoder.layer.11.attention.output.LayerNorm.bias      ├─768
│    │    └─encoder.layer.11.intermediate.dense.weight            ├─2,359,296
│    │    └─encoder.layer.11.intermediate.dense.bias              ├─3,072
│    │    └─encoder.layer.11.output.dense.weight                  ├─2,359,296
│    │    └─encoder.layer.11.output.dense.bias                    ├─768
│    │    └─encoder.layer.11.output.LayerNorm.weight              ├─768
│    │    └─encoder.layer.11.output.LayerNorm.bias                └─768
│    │    └─RobertaEmbeddings: 3-1                                39,000,576
│    │    │    └─word_embeddings.weight                           ├─38,603,520
│    │    │    └─position_embeddings.weight                       ├─394,752
│    │    │    └─token_type_embeddings.weight                     ├─768
│    │    │    └─LayerNorm.weight                                 ├─768
│    │    │    └─LayerNorm.bias                                   └─768
│    │    └─RobertaEncoder: 3-2                                   85,054,464
│    │    │    └─layer.0.attention.self.query.bias                ├─768
│    │    │    └─layer.0.attention.self.query.weight              ├─589,824
│    │    │    └─layer.0.attention.self.key.bias                  ├─768
│    │    │    └─layer.0.attention.self.key.weight                ├─589,824
│    │    │    └─layer.0.attention.self.value.bias                ├─768
│    │    │    └─layer.0.attention.self.value.weight              ├─589,824
│    │    │    └─layer.0.attention.output.dense.weight            ├─589,824
│    │    │    └─layer.0.attention.output.dense.bias              ├─768
│    │    │    └─layer.0.attention.output.LayerNorm.weight        ├─768
│    │    │    └─layer.0.attention.output.LayerNorm.bias          ├─768
│    │    │    └─layer.0.intermediate.dense.weight                ├─2,359,296
│    │    │    └─layer.0.intermediate.dense.bias                  ├─3,072
│    │    │    └─layer.0.output.dense.weight                      ├─2,359,296
│    │    │    └─layer.0.output.dense.bias                        ├─768
│    │    │    └─layer.0.output.LayerNorm.weight                  ├─768
│    │    │    └─layer.0.output.LayerNorm.bias                    ├─768
│    │    │    └─layer.1.attention.self.query.bias                ├─768
│    │    │    └─layer.1.attention.self.query.weight              ├─589,824
│    │    │    └─layer.1.attention.self.key.bias                  ├─768
│    │    │    └─layer.1.attention.self.key.weight                ├─589,824
│    │    │    └─layer.1.attention.self.value.bias                ├─768
│    │    │    └─layer.1.attention.self.value.weight              ├─589,824
│    │    │    └─layer.1.attention.output.dense.weight            ├─589,824
│    │    │    └─layer.1.attention.output.dense.bias              ├─768
│    │    │    └─layer.1.attention.output.LayerNorm.weight        ├─768
│    │    │    └─layer.1.attention.output.LayerNorm.bias          ├─768
│    │    │    └─layer.1.intermediate.dense.weight                ├─2,359,296
│    │    │    └─layer.1.intermediate.dense.bias                  ├─3,072
│    │    │    └─layer.1.output.dense.weight                      ├─2,359,296
│    │    │    └─layer.1.output.dense.bias                        ├─768
│    │    │    └─layer.1.output.LayerNorm.weight                  ├─768
│    │    │    └─layer.1.output.LayerNorm.bias                    ├─768
│    │    │    └─layer.2.attention.self.query.bias                ├─768
│    │    │    └─layer.2.attention.self.query.weight              ├─589,824
│    │    │    └─layer.2.attention.self.key.bias                  ├─768
│    │    │    └─layer.2.attention.self.key.weight                ├─589,824
│    │    │    └─layer.2.attention.self.value.bias                ├─768
│    │    │    └─layer.2.attention.self.value.weight              ├─589,824
│    │    │    └─layer.2.attention.output.dense.weight            ├─589,824
│    │    │    └─layer.2.attention.output.dense.bias              ├─768
│    │    │    └─layer.2.attention.output.LayerNorm.weight        ├─768
│    │    │    └─layer.2.attention.output.LayerNorm.bias          ├─768
│    │    │    └─layer.2.intermediate.dense.weight                ├─2,359,296
│    │    │    └─layer.2.intermediate.dense.bias                  ├─3,072
│    │    │    └─layer.2.output.dense.weight                      ├─2,359,296
│    │    │    └─layer.2.output.dense.bias                        ├─768
│    │    │    └─layer.2.output.LayerNorm.weight                  ├─768
│    │    │    └─layer.2.output.LayerNorm.bias                    ├─768
│    │    │    └─layer.3.attention.self.query.bias                ├─768
│    │    │    └─layer.3.attention.self.query.weight              ├─589,824
│    │    │    └─layer.3.attention.self.key.bias                  ├─768
│    │    │    └─layer.3.attention.self.key.weight                ├─589,824
│    │    │    └─layer.3.attention.self.value.bias                ├─768
│    │    │    └─layer.3.attention.self.value.weight              ├─589,824
│    │    │    └─layer.3.attention.output.dense.weight            ├─589,824
│    │    │    └─layer.3.attention.output.dense.bias              ├─768
│    │    │    └─layer.3.attention.output.LayerNorm.weight        ├─768
│    │    │    └─layer.3.attention.output.LayerNorm.bias          ├─768
│    │    │    └─layer.3.intermediate.dense.weight                ├─2,359,296
│    │    │    └─layer.3.intermediate.dense.bias                  ├─3,072
│    │    │    └─layer.3.output.dense.weight                      ├─2,359,296
│    │    │    └─layer.3.output.dense.bias                        ├─768
│    │    │    └─layer.3.output.LayerNorm.weight                  ├─768
│    │    │    └─layer.3.output.LayerNorm.bias                    ├─768
│    │    │    └─layer.4.attention.self.query.bias                ├─768
│    │    │    └─layer.4.attention.self.query.weight              ├─589,824
│    │    │    └─layer.4.attention.self.key.bias                  ├─768
│    │    │    └─layer.4.attention.self.key.weight                ├─589,824
│    │    │    └─layer.4.attention.self.value.bias                ├─768
│    │    │    └─layer.4.attention.self.value.weight              ├─589,824
│    │    │    └─layer.4.attention.output.dense.weight            ├─589,824
│    │    │    └─layer.4.attention.output.dense.bias              ├─768
│    │    │    └─layer.4.attention.output.LayerNorm.weight        ├─768
│    │    │    └─layer.4.attention.output.LayerNorm.bias          ├─768
│    │    │    └─layer.4.intermediate.dense.weight                ├─2,359,296
│    │    │    └─layer.4.intermediate.dense.bias                  ├─3,072
│    │    │    └─layer.4.output.dense.weight                      ├─2,359,296
│    │    │    └─layer.4.output.dense.bias                        ├─768
│    │    │    └─layer.4.output.LayerNorm.weight                  ├─768
│    │    │    └─layer.4.output.LayerNorm.bias                    ├─768
│    │    │    └─layer.5.attention.self.query.bias                ├─768
│    │    │    └─layer.5.attention.self.query.weight              ├─589,824
│    │    │    └─layer.5.attention.self.key.bias                  ├─768
│    │    │    └─layer.5.attention.self.key.weight                ├─589,824
│    │    │    └─layer.5.attention.self.value.bias                ├─768
│    │    │    └─layer.5.attention.self.value.weight              ├─589,824
│    │    │    └─layer.5.attention.output.dense.weight            ├─589,824
│    │    │    └─layer.5.attention.output.dense.bias              ├─768
│    │    │    └─layer.5.attention.output.LayerNorm.weight        ├─768
│    │    │    └─layer.5.attention.output.LayerNorm.bias          ├─768
│    │    │    └─layer.5.intermediate.dense.weight                ├─2,359,296
│    │    │    └─layer.5.intermediate.dense.bias                  ├─3,072
│    │    │    └─layer.5.output.dense.weight                      ├─2,359,296
│    │    │    └─layer.5.output.dense.bias                        ├─768
│    │    │    └─layer.5.output.LayerNorm.weight                  ├─768
│    │    │    └─layer.5.output.LayerNorm.bias                    ├─768
│    │    │    └─layer.6.attention.self.query.bias                ├─768
│    │    │    └─layer.6.attention.self.query.weight              ├─589,824
│    │    │    └─layer.6.attention.self.key.bias                  ├─768
│    │    │    └─layer.6.attention.self.key.weight                ├─589,824
│    │    │    └─layer.6.attention.self.value.bias                ├─768
│    │    │    └─layer.6.attention.self.value.weight              ├─589,824
│    │    │    └─layer.6.attention.output.dense.weight            ├─589,824
│    │    │    └─layer.6.attention.output.dense.bias              ├─768
│    │    │    └─layer.6.attention.output.LayerNorm.weight        ├─768
│    │    │    └─layer.6.attention.output.LayerNorm.bias          ├─768
│    │    │    └─layer.6.intermediate.dense.weight                ├─2,359,296
│    │    │    └─layer.6.intermediate.dense.bias                  ├─3,072
│    │    │    └─layer.6.output.dense.weight                      ├─2,359,296
│    │    │    └─layer.6.output.dense.bias                        ├─768
│    │    │    └─layer.6.output.LayerNorm.weight                  ├─768
│    │    │    └─layer.6.output.LayerNorm.bias                    ├─768
│    │    │    └─layer.7.attention.self.query.bias                ├─768
│    │    │    └─layer.7.attention.self.query.weight              ├─589,824
│    │    │    └─layer.7.attention.self.key.bias                  ├─768
│    │    │    └─layer.7.attention.self.key.weight                ├─589,824
│    │    │    └─layer.7.attention.self.value.bias                ├─768
│    │    │    └─layer.7.attention.self.value.weight              ├─589,824
│    │    │    └─layer.7.attention.output.dense.weight            ├─589,824
│    │    │    └─layer.7.attention.output.dense.bias              ├─768
│    │    │    └─layer.7.attention.output.LayerNorm.weight        ├─768
│    │    │    └─layer.7.attention.output.LayerNorm.bias          ├─768
│    │    │    └─layer.7.intermediate.dense.weight                ├─2,359,296
│    │    │    └─layer.7.intermediate.dense.bias                  ├─3,072
│    │    │    └─layer.7.output.dense.weight                      ├─2,359,296
│    │    │    └─layer.7.output.dense.bias                        ├─768
│    │    │    └─layer.7.output.LayerNorm.weight                  ├─768
│    │    │    └─layer.7.output.LayerNorm.bias                    ├─768
│    │    │    └─layer.8.attention.self.query.bias                ├─768
│    │    │    └─layer.8.attention.self.query.weight              ├─589,824
│    │    │    └─layer.8.attention.self.key.bias                  ├─768
│    │    │    └─layer.8.attention.self.key.weight                ├─589,824
│    │    │    └─layer.8.attention.self.value.bias                ├─768
│    │    │    └─layer.8.attention.self.value.weight              ├─589,824
│    │    │    └─layer.8.attention.output.dense.weight            ├─589,824
│    │    │    └─layer.8.attention.output.dense.bias              ├─768
│    │    │    └─layer.8.attention.output.LayerNorm.weight        ├─768
│    │    │    └─layer.8.attention.output.LayerNorm.bias          ├─768
│    │    │    └─layer.8.intermediate.dense.weight                ├─2,359,296
│    │    │    └─layer.8.intermediate.dense.bias                  ├─3,072
│    │    │    └─layer.8.output.dense.weight                      ├─2,359,296
│    │    │    └─layer.8.output.dense.bias                        ├─768
│    │    │    └─layer.8.output.LayerNorm.weight                  ├─768
│    │    │    └─layer.8.output.LayerNorm.bias                    ├─768
│    │    │    └─layer.9.attention.self.query.bias                ├─768
│    │    │    └─layer.9.attention.self.query.weight              ├─589,824
│    │    │    └─layer.9.attention.self.key.bias                  ├─768
│    │    │    └─layer.9.attention.self.key.weight                ├─589,824
│    │    │    └─layer.9.attention.self.value.bias                ├─768
│    │    │    └─layer.9.attention.self.value.weight              ├─589,824
│    │    │    └─layer.9.attention.output.dense.weight            ├─589,824
│    │    │    └─layer.9.attention.output.dense.bias              ├─768
│    │    │    └─layer.9.attention.output.LayerNorm.weight        ├─768
│    │    │    └─layer.9.attention.output.LayerNorm.bias          ├─768
│    │    │    └─layer.9.intermediate.dense.weight                ├─2,359,296
│    │    │    └─layer.9.intermediate.dense.bias                  ├─3,072
│    │    │    └─layer.9.output.dense.weight                      ├─2,359,296
│    │    │    └─layer.9.output.dense.bias                        ├─768
│    │    │    └─layer.9.output.LayerNorm.weight                  ├─768
│    │    │    └─layer.9.output.LayerNorm.bias                    ├─768
│    │    │    └─layer.10.attention.self.query.bias               ├─768
│    │    │    └─layer.10.attention.self.query.weight             ├─589,824
│    │    │    └─layer.10.attention.self.key.bias                 ├─768
│    │    │    └─layer.10.attention.self.key.weight               ├─589,824
│    │    │    └─layer.10.attention.self.value.bias               ├─768
│    │    │    └─layer.10.attention.self.value.weight             ├─589,824
│    │    │    └─layer.10.attention.output.dense.weight           ├─589,824
│    │    │    └─layer.10.attention.output.dense.bias             ├─768
│    │    │    └─layer.10.attention.output.LayerNorm.weight       ├─768
│    │    │    └─layer.10.attention.output.LayerNorm.bias         ├─768
│    │    │    └─layer.10.intermediate.dense.weight               ├─2,359,296
│    │    │    └─layer.10.intermediate.dense.bias                 ├─3,072
│    │    │    └─layer.10.output.dense.weight                     ├─2,359,296
│    │    │    └─layer.10.output.dense.bias                       ├─768
│    │    │    └─layer.10.output.LayerNorm.weight                 ├─768
│    │    │    └─layer.10.output.LayerNorm.bias                   ├─768
│    │    │    └─layer.11.attention.self.query.bias               ├─768
│    │    │    └─layer.11.attention.self.query.weight             ├─589,824
│    │    │    └─layer.11.attention.self.key.bias                 ├─768
│    │    │    └─layer.11.attention.self.key.weight               ├─589,824
│    │    │    └─layer.11.attention.self.value.bias               ├─768
│    │    │    └─layer.11.attention.self.value.weight             ├─589,824
│    │    │    └─layer.11.attention.output.dense.weight           ├─589,824
│    │    │    └─layer.11.attention.output.dense.bias             ├─768
│    │    │    └─layer.11.attention.output.LayerNorm.weight       ├─768
│    │    │    └─layer.11.attention.output.LayerNorm.bias         ├─768
│    │    │    └─layer.11.intermediate.dense.weight               ├─2,359,296
│    │    │    └─layer.11.intermediate.dense.bias                 ├─3,072
│    │    │    └─layer.11.output.dense.weight                     ├─2,359,296
│    │    │    └─layer.11.output.dense.bias                       ├─768
│    │    │    └─layer.11.output.LayerNorm.weight                 ├─768
│    │    │    └─layer.11.output.LayerNorm.bias                   └─768
│    └─RobertaClassificationHead: 2-2                             --
│    │    └─dense.weight                                          ├─589,824
│    │    └─dense.bias                                            ├─768
│    │    └─out_proj.weight                                       ├─768
│    │    └─out_proj.bias                                         └─1
│    │    └─Linear: 3-3                                           590,592
│    │    │    └─weight                                           ├─589,824
│    │    │    └─bias                                             └─768
│    │    └─Dropout: 3-4                                          --
│    │    └─Linear: 3-5                                           769
│    │    │    └─weight                                           ├─768
│    │    │    └─bias                                             └─1
├─Dropout: 1-2                                                    --
==========================================================================================
Total params: 124,646,401
Trainable params: 124,646,401
Non-trainable params: 0
03/25/2025 11:51:10 - INFO - __main__ -   ***** Running evaluation *****
03/25/2025 11:51:10 - INFO - __main__ -     Num examples = 2732
03/25/2025 11:51:10 - INFO - __main__ -     Batch size = 64
==========================================================================================
03/25/2025 11:56:58 - INFO - __main__ -   Average time: 7.391269340071568
03/25/2025 11:56:58 - INFO - __main__ -   ***** Eval results *****
03/25/2025 11:56:58 - INFO - __main__ -     eval_acc = 0.6439
03/25/2025 11:56:58 - INFO - __main__ -     eval_loss = 0.7432
03/25/2025 11:57:18 - INFO - __main__ -   ***** Running Test *****
03/25/2025 11:57:18 - INFO - __main__ -     Num examples = 2732
03/25/2025 11:57:18 - INFO - __main__ -     Batch size = 64
  0%|          | 0/43 [00:00<?, ?it/s]  2%|▏         | 1/43 [00:07<05:27,  7.80s/it]  5%|▍         | 2/43 [00:15<05:10,  7.58s/it]  7%|▋         | 3/43 [00:22<04:59,  7.48s/it]  9%|▉         | 4/43 [00:29<04:49,  7.43s/it] 12%|█▏        | 5/43 [00:37<04:40,  7.38s/it] 14%|█▍        | 6/43 [00:44<04:33,  7.39s/it] 16%|█▋        | 7/43 [00:52<04:26,  7.39s/it] 19%|█▊        | 8/43 [00:59<04:18,  7.39s/it] 21%|██        | 9/43 [01:06<04:11,  7.40s/it] 23%|██▎       | 10/43 [01:14<04:04,  7.40s/it] 26%|██▌       | 11/43 [01:21<03:56,  7.40s/it] 28%|██▊       | 12/43 [01:29<03:49,  7.41s/it] 30%|███       | 13/43 [01:36<03:43,  7.46s/it] 33%|███▎      | 14/43 [01:44<03:36,  7.46s/it] 35%|███▍      | 15/43 [01:51<03:28,  7.44s/it] 37%|███▋      | 16/43 [01:59<03:21,  7.46s/it] 40%|███▉      | 17/43 [02:06<03:14,  7.47s/it] 42%|████▏     | 18/43 [02:13<03:05,  7.43s/it] 44%|████▍     | 19/43 [02:21<02:58,  7.46s/it] 47%|████▋     | 20/43 [02:28<02:51,  7.45s/it] 49%|████▉     | 21/43 [02:36<02:43,  7.43s/it] 51%|█████     | 22/43 [02:43<02:35,  7.41s/it] 53%|█████▎    | 23/43 [02:50<02:28,  7.40s/it] 56%|█████▌    | 24/43 [02:58<02:21,  7.44s/it] 58%|█████▊    | 25/43 [03:05<02:13,  7.43s/it] 60%|██████    | 26/43 [03:13<02:06,  7.44s/it] 63%|██████▎   | 27/43 [03:20<01:59,  7.44s/it] 65%|██████▌   | 28/43 [03:28<01:51,  7.43s/it] 67%|██████▋   | 29/43 [03:35<01:44,  7.45s/it] 70%|██████▉   | 30/43 [03:43<01:36,  7.43s/it] 72%|███████▏  | 31/43 [03:50<01:29,  7.44s/it] 74%|███████▍  | 32/43 [03:57<01:21,  7.43s/it] 77%|███████▋  | 33/43 [04:05<01:14,  7.49s/it] 79%|███████▉  | 34/43 [04:13<01:07,  7.48s/it] 81%|████████▏ | 35/43 [04:20<00:59,  7.45s/it] 84%|████████▎ | 36/43 [04:27<00:52,  7.46s/it] 86%|████████▌ | 37/43 [04:35<00:44,  7.45s/it] 88%|████████▊ | 38/43 [04:42<00:37,  7.46s/it] 91%|█████████ | 39/43 [04:50<00:29,  7.45s/it] 93%|█████████▎| 40/43 [04:57<00:22,  7.46s/it] 95%|█████████▌| 41/43 [05:05<00:14,  7.44s/it] 98%|█████████▊| 42/43 [05:12<00:07,  7.42s/it]100%|██████████| 43/43 [05:17<00:00,  6.79s/it]100%|██████████| 43/43 [05:17<00:00,  7.39s/it]
03/25/2025 12:02:36 - INFO - __main__ -   Average inference time: 7.357994750488636
