==================================
Quick Test: CodeGPT Fine-tuning
==================================
[Info] Device: cuda
[Info] Carico modello da gpt2
[Info] Modello: gpt2, Params: 124,439,808
[Info] Carico dataset CodeSearchNet-Python
[Info] Carico CodeSearchNet-Python split=train
Preprocessing:   0%|          | 0/412178 [00:00<?, ?it/s]Preprocessing:   0%|          | 1/412178 [00:00<17:55:07,  6.39it/s]Preprocessing:   0%|          | 99/412178 [00:00<13:41, 501.37it/s] 
[Info] Caricati 100 esempi validi
[Info] Carico CodeSearchNet-Python split=validation
Preprocessing:   0%|          | 0/23107 [00:00<?, ?it/s]Preprocessing:   0%|          | 30/23107 [00:00<01:17, 299.49it/s]Preprocessing:   0%|          | 49/23107 [00:00<00:49, 463.85it/s]
WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[Info] Caricati 50 esempi validi
[Info] Train size: 100, Eval size: 50

[Training] Inizio fine-tuning...
  0%|          | 0/25 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
  4%|▍         | 1/25 [00:08<03:19,  8.33s/it]  8%|▊         | 2/25 [00:08<01:23,  3.65s/it] 12%|█▏        | 3/25 [00:09<00:47,  2.15s/it] 16%|█▌        | 4/25 [00:09<00:30,  1.45s/it] 20%|██        | 5/25 [00:09<00:21,  1.06s/it] 24%|██▍       | 6/25 [00:10<00:15,  1.20it/s] 28%|██▊       | 7/25 [00:10<00:12,  1.47it/s] 32%|███▏      | 8/25 [00:10<00:09,  1.71it/s] 36%|███▌      | 9/25 [00:11<00:08,  1.92it/s] 40%|████      | 10/25 [00:11<00:07,  2.10it/s]                                                40%|████      | 10/25 [00:11<00:07,  2.10it/s] 44%|████▍     | 11/25 [00:12<00:06,  2.10it/s] 48%|████▊     | 12/25 [00:12<00:05,  2.24it/s] 52%|█████▏    | 13/25 [00:12<00:05,  2.35it/s] 56%|█████▌    | 14/25 [00:13<00:04,  2.43it/s] 60%|██████    | 15/25 [00:13<00:04,  2.49it/s] 64%|██████▍   | 16/25 [00:14<00:03,  2.54it/s] 68%|██████▊   | 17/25 [00:14<00:03,  2.57it/s] 72%|███████▏  | 18/25 [00:14<00:02,  2.59it/s] 76%|███████▌  | 19/25 [00:15<00:02,  2.61it/s] 80%|████████  | 20/25 [00:15<00:01,  2.62it/s]                                                80%|████████  | 20/25 [00:15<00:01,  2.62it/s] 84%|████████▍ | 21/25 [00:15<00:01,  2.63it/s] 88%|████████▊ | 22/25 [00:16<00:01,  2.64it/s] 92%|█████████▏| 23/25 [00:16<00:00,  2.64it/s] 96%|█████████▌| 24/25 [00:17<00:00,  2.64it/s]100%|██████████| 25/25 [00:17<00:00,  2.53it/s]                                               100%|██████████| 25/25 [00:24<00:00,  2.53it/s]100%|██████████| 25/25 [00:24<00:00,  1.01it/s]
{'loss': 2.8253, 'grad_norm': 13.549676895141602, 'learning_rate': 9e-07, 'epoch': 0.4}
{'loss': 2.6904, 'grad_norm': 19.16505241394043, 'learning_rate': 1.9e-06, 'epoch': 0.8}
{'train_runtime': 24.674, 'train_samples_per_second': 4.053, 'train_steps_per_second': 1.013, 'train_loss': 2.7411536026000975, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               =    12167GF
  train_loss               =     2.7412
  train_runtime            = 0:00:24.67
  train_samples_per_second =      4.053
  train_steps_per_second   =      1.013
[Training] Completato. Modello salvato in ./test_output

[Evaluation] Valutazione su CodeSearchNet validation set...
  0%|          | 0/13 [00:00<?, ?it/s] 15%|█▌        | 2/13 [00:00<00:00, 18.30it/s] 31%|███       | 4/13 [00:00<00:00, 10.73it/s] 46%|████▌     | 6/13 [00:00<00:00,  9.52it/s] 62%|██████▏   | 8/13 [00:00<00:00,  9.05it/s] 69%|██████▉   | 9/13 [00:00<00:00,  8.89it/s] 77%|███████▋  | 10/13 [00:01<00:00,  8.77it/s] 85%|████████▍ | 11/13 [00:01<00:00,  8.66it/s] 92%|█████████▏| 12/13 [00:01<00:00,  8.58it/s]100%|██████████| 13/13 [00:01<00:00,  7.56it/s]100%|██████████| 13/13 [00:01<00:00,  8.52it/s]
***** eval metrics *****
  epoch                   =        1.0
  eval_loss               =      2.381
  eval_runtime            = 0:00:01.67
  eval_samples_per_second =     29.852
  eval_steps_per_second   =      7.761
[Evaluation] Eval loss: 2.3810

[Done] Pipeline completato!

==================================
Test completato!
Se non ci sono errori, esegui il training completo con:
  bash run_codegpt_finetune.sh
o
  sbatch run_codegpt_finetune.sh
==================================
