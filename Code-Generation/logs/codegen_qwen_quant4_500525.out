Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:08<00:26,  8.78s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:18<00:18,  9.24s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:27<00:09,  9.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:35<00:00,  8.66s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:35<00:00,  8.86s/it]
/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
INFO:__main__:Eseguendo warmup del modello...
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
INFO:__main__:Warmup completato.
INFO:__main__:Generando 100 samples per 164 tasks...
INFO:__main__:Batch 1/100
/pytorch/aten/src/ATen/native/cuda/TensorCompare.cu:112: _assert_async_cuda_kernel: block: [0,0,0], thread: [0,0,0] Assertion `probability tensor contains either `inf`, `nan` or element < 0` failed.
Size (MB): 5647.536912
Traceback (most recent call last):
  File "/NFSHOME/gdaloisio/code/CodeXGLUE/Code-Generation/generation.py", line 246, in <module>
    batch_samples, batch_times = generate_batch_completions(
                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        model=model,
        ^^^^^^^^^^^^
    ...<5 lines>...
        model_device=model_device,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/NFSHOME/gdaloisio/code/CodeXGLUE/Code-Generation/generation.py", line 59, in generate_batch_completions
    outputs = model.generate(
        input_ids=enc["input_ids"],
        attention_mask=enc.get("attention_mask"),
        **gen_kwargs,
    )
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/transformers/generation/utils.py", line 2597, in generate
    result = self._sample(
        input_ids,
    ...<5 lines>...
        **model_kwargs,
    )
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/transformers/generation/utils.py", line 3548, in _sample
    while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):
          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.13/site-packages/transformers/generation/utils.py", line 2748, in _has_unfinished_sequences
    elif this_peer_finished:
         ^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

srun: error: compute-0-3: task 0: Exited with exit code 1
