05/15/2025 17:51:02 - INFO - __main__ -   Namespace(model_type='t5', model_name_or_path='Salesforce/codet5-base', output_dir='model_t5/java', load_model_path='model_t5/java/checkpoint-best-bleu/pytorch_model.bin', train_filename=None, dev_filename=None, test_filename='../dataset/java/test.jsonl', config_name='', tokenizer_name='', max_source_length=256, max_target_length=128, do_train=False, do_eval=False, do_test=True, do_lower_case=False, no_cuda=True, quantize=False, quantize4=True, quantizef8=False, prune=False, prune4=False, prune6=False, do_retrain=False, train_batch_size=8, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42, job_id='488447', file_len=300)
05/15/2025 17:51:02 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False
05/15/2025 17:51:06 - INFO - __main__ -   reload model from model_t5/java/checkpoint-best-bleu/pytorch_model.bin
05/15/2025 17:51:07 - INFO - __main__ -   Apply quantization qint4
05/15/2025 17:51:12 - INFO - __main__ -   ******* Calibration **************
  0%|          | 0/172 [00:00<?, ?it/s]/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.9/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
