07/15/2024 17:41:28 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='model/java', load_model_path='model/java/checkpoint-best-bleu/pytorch_model.bin', train_filename=None, dev_filename=None, test_filename='../dataset/java/test.jsonl', config_name='', tokenizer_name='', max_source_length=256, max_target_length=128, do_train=False, do_eval=False, do_test=True, do_lower_case=False, no_cuda=True, quantize=False, quantize4=False, quantizef8=False, prune=False, prune4=False, prune6=False, train_batch_size=8, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42, job_id='12199', file_len=300)
07/15/2024 17:41:28 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False
07/15/2024 17:41:38 - INFO - __main__ -   reload model from model/java/checkpoint-best-bleu/pytorch_model.bin
07/15/2024 17:41:53 - INFO - __main__ -   Test file: ../dataset/java/test.jsonl
  0%|          | 0/172 [00:00<?, ?it/s]  1%|          | 1/172 [08:16<23:34:52, 496.45s/it]  1%|          | 2/172 [41:24<64:53:24, 1374.14s/it]  2%|▏         | 3/172 [1:38:50<108:54:28, 2319.93s/it]  2%|▏         | 4/172 [2:47:48<141:45:58, 3037.85s/it]  3%|▎         | 5/172 [3:50:32<153:04:12, 3299.72s/it]  3%|▎         | 6/172 [5:12:07<177:09:23, 3841.95s/it]  4%|▍         | 7/172 [6:43:42<200:51:36, 4382.40s/it]  5%|▍         | 8/172 [8:08:00<209:26:41, 4597.57s/it]  5%|▌         | 9/172 [9:38:13<219:42:34, 4852.48s/it]  6%|▌         | 10/172 [11:01:20<220:14:01, 4894.08s/it]  6%|▋         | 11/172 [12:26:39<221:56:29, 4962.67s/it]  7%|▋         | 12/172 [13:54:06<224:24:45, 5049.28s/it]  8%|▊         | 13/172 [15:20:57<225:10:36, 5098.34s/it]  8%|▊         | 14/172 [16:22:54<205:26:55, 4681.11s/it]  9%|▊         | 15/172 [18:02:41<221:18:20, 5074.53s/it]  9%|▉         | 16/172 [19:43:04<232:16:04, 5360.03s/it] 10%|▉         | 17/172 [21:18:47<235:44:41, 5475.36s/it] 10%|█         | 18/172 [22:58:40<240:52:21, 5630.79s/it] 11%|█         | 19/172 [24:05:51<218:53:32, 5150.41s/it] 12%|█▏        | 20/172 [25:41:53<225:12:56, 5334.06s/it] 12%|█▏        | 21/172 [27:12:46<225:13:58, 5369.79s/it] 13%|█▎        | 22/172 [28:44:58<225:45:42, 5418.29s/it] 13%|█▎        | 23/172 [30:27:19<233:14:09, 5635.23s/it] 14%|█▍        | 24/172 [31:44:20<219:09:31, 5330.89s/it] 15%|█▍        | 25/172 [33:22:04<224:13:00, 5491.02s/it] 15%|█▌        | 26/172 [35:06:37<232:11:57, 5725.46s/it] 16%|█▌        | 27/172 [36:46:40<233:58:00, 5808.83s/it] 16%|█▋        | 28/172 [38:41:09<245:04:05, 6126.71s/it] 17%|█▋        | 29/172 [40:28:21<247:00:18, 6218.31s/it] 17%|█▋        | 30/172 [42:25:18<254:44:10, 6458.10s/it] 18%|█▊        | 31/172 [44:28:45<264:05:04, 6742.59s/it] 19%|█▊        | 32/172 [46:34:50<271:48:29, 6989.36s/it] 19%|█▉        | 33/172 [48:38:17<274:42:23, 7114.70s/it] 20%|█▉        | 34/172 