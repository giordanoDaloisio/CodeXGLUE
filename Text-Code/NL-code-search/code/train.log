03/24/2025 12:40:44 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
03/24/2025 12:40:44 - DEBUG - urllib3.connectionpool -   Starting new HTTPS connection (1): huggingface.co:443
03/24/2025 12:40:45 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /microsoft/graphcodebert-base/resolve/main/config.json HTTP/11" 200 0
03/24/2025 12:40:45 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /roberta-base/resolve/main/tokenizer_config.json HTTP/11" 200 0
03/24/2025 12:40:45 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /microsoft/graphcodebert-base/resolve/main/model.safetensors HTTP/11" 404 0
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
03/24/2025 12:40:46 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../dataset/train.jsonl', output_dir='./saved_models_graph', eval_data_file='../dataset/valid.jsonl', test_data_file='../dataset/test.jsonl', model_type='roberta', model_name_or_path='microsoft/graphcodebert-base', mlm=False, mlm_probability=0.15, config_name='microsoft/graphcodebert-base', tokenizer_name='roberta-base', cache_dir='', block_size=256, do_train=True, do_eval=False, do_test=False, evaluate_during_training=True, do_lower_case=False, train_batch_size=32, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=123456, epoch=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', quantize=False, quantize4=False, quantizef8=False, prune=False, prune4=False, prune6=False, job_id=None, n_gpu=1, device=device(type='cuda'), per_gpu_train_batch_size=32, per_gpu_eval_batch_size=64, start_epoch=0, start_step=0)
03/24/2025 12:44:31 - INFO - __main__ -   *** Example ***
03/24/2025 12:44:31 - INFO - __main__ -   idx: 0
03/24/2025 12:44:31 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"', '__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_"', ';"', '_)', '_[', '_0', '_]', '</s>']
03/24/2025 12:44:31 - INFO - __main__ -   code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/24/2025 12:44:31 - INFO - __main__ -   nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']
03/24/2025 12:44:31 - INFO - __main__ -   nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/24/2025 12:44:31 - INFO - __main__ -   *** Example ***
03/24/2025 12:44:31 - INFO - __main__ -   idx: 1
03/24/2025 12:44:31 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."', '""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']
03/24/2025 12:44:31 - INFO - __main__ -   code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/24/2025 12:44:31 - INFO - __main__ -   nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
03/24/2025 12:44:31 - INFO - __main__ -   nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/24/2025 12:44:31 - INFO - __main__ -   *** Example ***
03/24/2025 12:44:31 - INFO - __main__ -   idx: 2
03/24/2025 12:44:31 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
03/24/2025 12:44:31 - INFO - __main__ -   code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/24/2025 12:44:31 - INFO - __main__ -   nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
03/24/2025 12:44:31 - INFO - __main__ -   nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
03/24/2025 12:44:39 - INFO - __main__ -   ***** Running training *****
03/24/2025 12:44:39 - INFO - __main__ -     Num examples = 251820
03/24/2025 12:44:39 - INFO - __main__ -     Num Epochs = 2
03/24/2025 12:44:39 - INFO - __main__ -     Instantaneous batch size per GPU = 32
03/24/2025 12:44:39 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
03/24/2025 12:44:39 - INFO - __main__ -     Gradient Accumulation steps = 1
03/24/2025 12:44:39 - INFO - __main__ -     Total optimization steps = 15740
03/24/2025 12:51:29 - INFO - __main__ -   epoch 0 step 100 loss 9.74496
03/24/2025 12:58:13 - INFO - __main__ -   epoch 0 step 200 loss 5.22279
03/24/2025 13:04:57 - INFO - __main__ -   epoch 0 step 300 loss 3.55906
03/24/2025 13:11:42 - INFO - __main__ -   epoch 0 step 400 loss 2.70915
03/24/2025 13:18:26 - INFO - __main__ -   epoch 0 step 500 loss 2.19857
03/24/2025 13:25:11 - INFO - __main__ -   epoch 0 step 600 loss 1.8612
03/24/2025 13:31:55 - INFO - __main__ -   epoch 0 step 700 loss 1.61405
03/24/2025 13:37:56 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 13:37:56 - INFO - __main__ -     Num examples = 9604
03/24/2025 13:37:56 - INFO - __main__ -     Batch size = 64
03/24/2025 13:45:03 - INFO - __main__ -     eval_loss = 1.1824
03/24/2025 13:45:03 - INFO - __main__ -     eval_mrr = 0.3871
03/24/2025 13:45:03 - INFO - __main__ -     ********************
03/24/2025 13:45:03 - INFO - __main__ -     Best mrr:0.3871
03/24/2025 13:45:03 - INFO - __main__ -     ********************
03/24/2025 13:45:04 - INFO - __main__ -   Saving model checkpoint to ./saved_models_graph/checkpoint-best-mrr/model.bin
03/24/2025 13:45:57 - INFO - __main__ -   epoch 0 step 800 loss 0.16165
03/24/2025 13:52:41 - INFO - __main__ -   epoch 0 step 900 loss 0.15085
03/24/2025 13:59:26 - INFO - __main__ -   epoch 0 step 1000 loss 0.16468
03/24/2025 14:06:13 - INFO - __main__ -   epoch 0 step 1100 loss 0.15732
03/24/2025 14:13:01 - INFO - __main__ -   epoch 0 step 1200 loss 0.15529
03/24/2025 14:19:49 - INFO - __main__ -   epoch 0 step 1300 loss 0.15798
03/24/2025 14:26:37 - INFO - __main__ -   epoch 0 step 1400 loss 0.15946
03/24/2025 14:33:25 - INFO - __main__ -   epoch 0 step 1500 loss 0.1601
03/24/2025 14:38:26 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 14:38:26 - INFO - __main__ -     Num examples = 9604
03/24/2025 14:38:26 - INFO - __main__ -     Batch size = 64
03/24/2025 14:45:35 - INFO - __main__ -     eval_loss = 1.7714
03/24/2025 14:45:35 - INFO - __main__ -     eval_mrr = 0.3057
03/24/2025 14:47:20 - INFO - __main__ -   epoch 0 step 1600 loss 0.18474
03/24/2025 14:54:05 - INFO - __main__ -   epoch 0 step 1700 loss 0.16199
03/24/2025 15:00:49 - INFO - __main__ -   epoch 0 step 1800 loss 0.16893
03/24/2025 15:07:34 - INFO - __main__ -   epoch 0 step 1900 loss 0.17899
03/24/2025 15:14:18 - INFO - __main__ -   epoch 0 step 2000 loss 0.17551
03/24/2025 15:21:02 - INFO - __main__ -   epoch 0 step 2100 loss 0.17403
03/24/2025 15:27:47 - INFO - __main__ -   epoch 0 step 2200 loss 0.1742
03/24/2025 15:34:31 - INFO - __main__ -   epoch 0 step 2300 loss 0.17253
03/24/2025 15:38:38 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 15:38:38 - INFO - __main__ -     Num examples = 9604
03/24/2025 15:38:38 - INFO - __main__ -     Batch size = 64
03/24/2025 15:45:44 - INFO - __main__ -     eval_loss = 1.4955
03/24/2025 15:45:44 - INFO - __main__ -     eval_mrr = 0.2969
03/24/2025 15:48:22 - INFO - __main__ -   epoch 0 step 2400 loss 0.17026
03/24/2025 15:55:07 - INFO - __main__ -   epoch 0 step 2500 loss 0.1767
03/24/2025 16:01:53 - INFO - __main__ -   epoch 0 step 2600 loss 0.16769
03/24/2025 16:08:37 - INFO - __main__ -   epoch 0 step 2700 loss 0.15465
03/24/2025 16:15:22 - INFO - __main__ -   epoch 0 step 2800 loss 0.1511
03/24/2025 16:22:07 - INFO - __main__ -   epoch 0 step 2900 loss 0.15512
03/24/2025 16:28:52 - INFO - __main__ -   epoch 0 step 3000 loss 0.15333
03/24/2025 16:35:37 - INFO - __main__ -   epoch 0 step 3100 loss 0.14961
03/24/2025 16:38:51 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 16:38:51 - INFO - __main__ -     Num examples = 9604
03/24/2025 16:38:51 - INFO - __main__ -     Batch size = 64
03/24/2025 16:45:58 - INFO - __main__ -     eval_loss = 1.4402
03/24/2025 16:45:58 - INFO - __main__ -     eval_mrr = 0.3038
03/24/2025 16:49:28 - INFO - __main__ -   epoch 0 step 3200 loss 0.18462
03/24/2025 16:56:13 - INFO - __main__ -   epoch 0 step 3300 loss 0.14678
03/24/2025 17:02:59 - INFO - __main__ -   epoch 0 step 3400 loss 0.14636
03/24/2025 17:09:43 - INFO - __main__ -   epoch 0 step 3500 loss 0.14398
03/24/2025 17:16:29 - INFO - __main__ -   epoch 0 step 3600 loss 0.14382
03/24/2025 17:23:14 - INFO - __main__ -   epoch 0 step 3700 loss 0.14244
03/24/2025 17:29:59 - INFO - __main__ -   epoch 0 step 3800 loss 0.14189
03/24/2025 17:36:45 - INFO - __main__ -   epoch 0 step 3900 loss 0.14001
03/24/2025 17:39:06 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 17:39:06 - INFO - __main__ -     Num examples = 9604
03/24/2025 17:39:06 - INFO - __main__ -     Batch size = 64
03/24/2025 17:46:13 - INFO - __main__ -     eval_loss = 1.6026
03/24/2025 17:46:13 - INFO - __main__ -     eval_mrr = 0.295
03/24/2025 17:50:36 - INFO - __main__ -   epoch 0 step 4000 loss 0.14277
03/24/2025 17:57:21 - INFO - __main__ -   epoch 0 step 4100 loss 0.15459
03/24/2025 18:04:06 - INFO - __main__ -   epoch 0 step 4200 loss 0.1373
03/24/2025 18:10:51 - INFO - __main__ -   epoch 0 step 4300 loss 0.13553
03/24/2025 18:17:37 - INFO - __main__ -   epoch 0 step 4400 loss 0.13347
03/24/2025 18:24:22 - INFO - __main__ -   epoch 0 step 4500 loss 0.13506
03/24/2025 18:31:07 - INFO - __main__ -   epoch 0 step 4600 loss 0.13449
03/24/2025 18:37:52 - INFO - __main__ -   epoch 0 step 4700 loss 0.13643
03/24/2025 18:39:21 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 18:39:21 - INFO - __main__ -     Num examples = 9604
03/24/2025 18:39:21 - INFO - __main__ -     Batch size = 64
03/24/2025 18:46:27 - INFO - __main__ -     eval_loss = 1.3565
03/24/2025 18:46:27 - INFO - __main__ -     eval_mrr = 0.3112
03/24/2025 18:51:43 - INFO - __main__ -   epoch 0 step 4800 loss 0.12329
03/24/2025 18:58:28 - INFO - __main__ -   epoch 0 step 4900 loss 0.13025
03/24/2025 19:05:13 - INFO - __main__ -   epoch 0 step 5000 loss 0.12031
03/24/2025 19:11:58 - INFO - __main__ -   epoch 0 step 5100 loss 0.12076
03/24/2025 19:18:44 - INFO - __main__ -   epoch 0 step 5200 loss 0.12679
03/24/2025 19:25:29 - INFO - __main__ -   epoch 0 step 5300 loss 0.12596
03/24/2025 19:32:14 - INFO - __main__ -   epoch 0 step 5400 loss 0.12593
03/24/2025 19:38:59 - INFO - __main__ -   epoch 0 step 5500 loss 0.12418
03/24/2025 19:39:35 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 19:39:35 - INFO - __main__ -     Num examples = 9604
03/24/2025 19:39:35 - INFO - __main__ -     Batch size = 64
03/24/2025 19:46:42 - INFO - __main__ -     eval_loss = 1.3211
03/24/2025 19:46:42 - INFO - __main__ -     eval_mrr = 0.3313
03/24/2025 19:52:50 - INFO - __main__ -   epoch 0 step 5600 loss 0.1271
03/24/2025 19:59:35 - INFO - __main__ -   epoch 0 step 5700 loss 0.11372
03/24/2025 20:06:21 - INFO - __main__ -   epoch 0 step 5800 loss 0.11644
03/24/2025 20:13:06 - INFO - __main__ -   epoch 0 step 5900 loss 0.12066
03/24/2025 20:19:51 - INFO - __main__ -   epoch 0 step 6000 loss 0.11608
03/24/2025 20:26:36 - INFO - __main__ -   epoch 0 step 6100 loss 0.11468
03/24/2025 20:33:21 - INFO - __main__ -   epoch 0 step 6200 loss 0.11435
03/24/2025 20:39:50 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 20:39:50 - INFO - __main__ -     Num examples = 9604
03/24/2025 20:39:50 - INFO - __main__ -     Batch size = 64
03/24/2025 20:46:56 - INFO - __main__ -     eval_loss = 1.2792
03/24/2025 20:46:56 - INFO - __main__ -     eval_mrr = 0.3496
03/24/2025 20:47:12 - INFO - __main__ -   epoch 0 step 6300 loss 0.12387
03/24/2025 20:53:57 - INFO - __main__ -   epoch 0 step 6400 loss 0.12135
03/24/2025 21:00:42 - INFO - __main__ -   epoch 0 step 6500 loss 0.10967
03/24/2025 21:07:27 - INFO - __main__ -   epoch 0 step 6600 loss 0.10024
03/24/2025 21:14:12 - INFO - __main__ -   epoch 0 step 6700 loss 0.10539
03/24/2025 21:20:56 - INFO - __main__ -   epoch 0 step 6800 loss 0.10162
03/24/2025 21:27:41 - INFO - __main__ -   epoch 0 step 6900 loss 0.10283
03/24/2025 21:34:26 - INFO - __main__ -   epoch 0 step 7000 loss 0.10215
03/24/2025 21:40:02 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 21:40:02 - INFO - __main__ -     Num examples = 9604
03/24/2025 21:40:02 - INFO - __main__ -     Batch size = 64
03/24/2025 21:47:09 - INFO - __main__ -     eval_loss = 1.3178
03/24/2025 21:47:09 - INFO - __main__ -     eval_mrr = 0.3419
03/24/2025 21:48:18 - INFO - __main__ -   epoch 0 step 7100 loss 0.09517
03/24/2025 21:55:03 - INFO - __main__ -   epoch 0 step 7200 loss 0.11401
03/24/2025 22:01:48 - INFO - __main__ -   epoch 0 step 7300 loss 0.12063
03/24/2025 22:08:33 - INFO - __main__ -   epoch 0 step 7400 loss 0.12153
03/24/2025 22:15:18 - INFO - __main__ -   epoch 0 step 7500 loss 0.11382
03/24/2025 22:22:03 - INFO - __main__ -   epoch 0 step 7600 loss 0.11308
03/24/2025 22:28:48 - INFO - __main__ -   epoch 0 step 7700 loss 0.114
03/24/2025 22:35:33 - INFO - __main__ -   epoch 0 step 7800 loss 0.1141
03/24/2025 22:40:15 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 22:40:15 - INFO - __main__ -     Num examples = 9604
03/24/2025 22:40:15 - INFO - __main__ -     Batch size = 64
03/24/2025 22:47:21 - INFO - __main__ -     eval_loss = 1.2701
03/24/2025 22:47:21 - INFO - __main__ -     eval_mrr = 0.3698
03/24/2025 22:54:07 - INFO - __main__ -   epoch 1 step 100 loss 0.04666
03/24/2025 23:00:52 - INFO - __main__ -   epoch 1 step 200 loss 0.06618
03/24/2025 23:07:37 - INFO - __main__ -   epoch 1 step 300 loss 0.06597
03/24/2025 23:14:22 - INFO - __main__ -   epoch 1 step 400 loss 0.06502
03/24/2025 23:21:07 - INFO - __main__ -   epoch 1 step 500 loss 0.06543
03/24/2025 23:27:52 - INFO - __main__ -   epoch 1 step 600 loss 0.06805
03/24/2025 23:34:37 - INFO - __main__ -   epoch 1 step 700 loss 0.06861
03/24/2025 23:40:31 - INFO - __main__ -   ***** Running evaluation *****
03/24/2025 23:40:31 - INFO - __main__ -     Num examples = 9604
03/24/2025 23:40:31 - INFO - __main__ -     Batch size = 64
03/24/2025 23:47:39 - INFO - __main__ -     eval_loss = 1.5435
03/24/2025 23:47:39 - INFO - __main__ -     eval_mrr = 0.3643
03/24/2025 23:48:32 - INFO - __main__ -   epoch 1 step 800 loss 0.11445
03/24/2025 23:55:16 - INFO - __main__ -   epoch 1 step 900 loss 0.06903
03/25/2025 00:02:01 - INFO - __main__ -   epoch 1 step 1000 loss 0.05779
03/25/2025 00:08:45 - INFO - __main__ -   epoch 1 step 1100 loss 0.06057
03/25/2025 00:15:30 - INFO - __main__ -   epoch 1 step 1200 loss 0.06109
03/25/2025 00:22:15 - INFO - __main__ -   epoch 1 step 1300 loss 0.06309
03/25/2025 00:28:59 - INFO - __main__ -   epoch 1 step 1400 loss 0.06104
03/25/2025 00:35:44 - INFO - __main__ -   epoch 1 step 1500 loss 0.06234
03/25/2025 00:40:44 - INFO - __main__ -   ***** Running evaluation *****
03/25/2025 00:40:44 - INFO - __main__ -     Num examples = 9604
03/25/2025 00:40:44 - INFO - __main__ -     Batch size = 64
03/25/2025 00:47:50 - INFO - __main__ -     eval_loss = 1.7653
03/25/2025 00:47:50 - INFO - __main__ -     eval_mrr = 0.346
03/25/2025 00:49:35 - INFO - __main__ -   epoch 1 step 1600 loss 0.03197
03/25/2025 00:56:20 - INFO - __main__ -   epoch 1 step 1700 loss 0.05736
03/25/2025 01:03:05 - INFO - __main__ -   epoch 1 step 1800 loss 0.05818
03/25/2025 01:09:50 - INFO - __main__ -   epoch 1 step 1900 loss 0.05558
03/25/2025 01:16:35 - INFO - __main__ -   epoch 1 step 2000 loss 0.06203
03/25/2025 01:23:19 - INFO - __main__ -   epoch 1 step 2100 loss 0.06294
03/25/2025 01:30:04 - INFO - __main__ -   epoch 1 step 2200 loss 0.06309
03/25/2025 01:36:48 - INFO - __main__ -   epoch 1 step 2300 loss 0.06442
03/25/2025 01:40:55 - INFO - __main__ -   ***** Running evaluation *****
03/25/2025 01:40:55 - INFO - __main__ -     Num examples = 9604
03/25/2025 01:40:55 - INFO - __main__ -     Batch size = 64
03/25/2025 01:48:01 - INFO - __main__ -     eval_loss = 1.2347
03/25/2025 01:48:01 - INFO - __main__ -     eval_mrr = 0.4058
03/25/2025 01:48:01 - INFO - __main__ -     ********************
03/25/2025 01:48:01 - INFO - __main__ -     Best mrr:0.4058
03/25/2025 01:48:01 - INFO - __main__ -     ********************
03/25/2025 01:48:03 - INFO - __main__ -   Saving model checkpoint to ./saved_models_graph/checkpoint-best-mrr/model.bin
03/25/2025 01:50:41 - INFO - __main__ -   epoch 1 step 2400 loss 0.05336
03/25/2025 01:57:25 - INFO - __main__ -   epoch 1 step 2500 loss 0.05242
03/25/2025 02:04:10 - INFO - __main__ -   epoch 1 step 2600 loss 0.0605
03/25/2025 02:10:54 - INFO - __main__ -   epoch 1 step 2700 loss 0.06402
03/25/2025 02:17:39 - INFO - __main__ -   epoch 1 step 2800 loss 0.06148
03/25/2025 02:24:23 - INFO - __main__ -   epoch 1 step 2900 loss 0.06086
03/25/2025 02:31:08 - INFO - __main__ -   epoch 1 step 3000 loss 0.05885
03/25/2025 02:37:52 - INFO - __main__ -   epoch 1 step 3100 loss 0.06105
03/25/2025 02:41:07 - INFO - __main__ -   ***** Running evaluation *****
03/25/2025 02:41:07 - INFO - __main__ -     Num examples = 9604
03/25/2025 02:41:07 - INFO - __main__ -     Batch size = 64
03/25/2025 02:48:13 - INFO - __main__ -     eval_loss = 1.1866
03/25/2025 02:48:13 - INFO - __main__ -     eval_mrr = 0.4148
03/25/2025 02:48:13 - INFO - __main__ -     ********************
03/25/2025 02:48:13 - INFO - __main__ -     Best mrr:0.4148
03/25/2025 02:48:13 - INFO - __main__ -     ********************
03/25/2025 02:48:14 - INFO - __main__ -   Saving model checkpoint to ./saved_models_graph/checkpoint-best-mrr/model.bin
03/25/2025 02:51:45 - INFO - __main__ -   epoch 1 step 3200 loss 0.0715
03/25/2025 02:58:29 - INFO - __main__ -   epoch 1 step 3300 loss 0.06141
03/25/2025 03:05:14 - INFO - __main__ -   epoch 1 step 3400 loss 0.05897
03/25/2025 03:11:59 - INFO - __main__ -   epoch 1 step 3500 loss 0.06119
03/25/2025 03:18:43 - INFO - __main__ -   epoch 1 step 3600 loss 0.05859
03/25/2025 03:25:28 - INFO - __main__ -   epoch 1 step 3700 loss 0.05582
03/25/2025 03:32:12 - INFO - __main__ -   epoch 1 step 3800 loss 0.05654
03/25/2025 03:38:57 - INFO - __main__ -   epoch 1 step 3900 loss 0.05584
03/25/2025 03:41:19 - INFO - __main__ -   ***** Running evaluation *****
03/25/2025 03:41:19 - INFO - __main__ -     Num examples = 9604
03/25/2025 03:41:19 - INFO - __main__ -     Batch size = 64
03/25/2025 03:48:25 - INFO - __main__ -     eval_loss = 1.257
03/25/2025 03:48:25 - INFO - __main__ -     eval_mrr = 0.4114
03/25/2025 03:52:48 - INFO - __main__ -   epoch 1 step 4000 loss 0.0628
03/25/2025 03:59:33 - INFO - __main__ -   epoch 1 step 4100 loss 0.05485
03/25/2025 04:06:18 - INFO - __main__ -   epoch 1 step 4200 loss 0.05965
03/25/2025 04:13:03 - INFO - __main__ -   epoch 1 step 4300 loss 0.05897
03/25/2025 04:19:47 - INFO - __main__ -   epoch 1 step 4400 loss 0.05672
03/25/2025 04:26:32 - INFO - __main__ -   epoch 1 step 4500 loss 0.0547
03/25/2025 04:33:16 - INFO - __main__ -   epoch 1 step 4600 loss 0.0532
03/25/2025 04:40:01 - INFO - __main__ -   epoch 1 step 4700 loss 0.05372
03/25/2025 04:41:30 - INFO - __main__ -   ***** Running evaluation *****
03/25/2025 04:41:30 - INFO - __main__ -     Num examples = 9604
03/25/2025 04:41:30 - INFO - __main__ -     Batch size = 64
03/25/2025 04:48:36 - INFO - __main__ -     eval_loss = 1.1366
03/25/2025 04:48:36 - INFO - __main__ -     eval_mrr = 0.4181
03/25/2025 04:48:36 - INFO - __main__ -     ********************
03/25/2025 04:48:36 - INFO - __main__ -     Best mrr:0.4181
03/25/2025 04:48:36 - INFO - __main__ -     ********************
03/25/2025 04:48:38 - INFO - __main__ -   Saving model checkpoint to ./saved_models_graph/checkpoint-best-mrr/model.bin
03/25/2025 04:53:54 - INFO - __main__ -   epoch 1 step 4800 loss 0.04781
03/25/2025 05:00:38 - INFO - __main__ -   epoch 1 step 4900 loss 0.05775
03/25/2025 05:07:23 - INFO - __main__ -   epoch 1 step 5000 loss 0.05227
03/25/2025 05:14:07 - INFO - __main__ -   epoch 1 step 5100 loss 0.05106
03/25/2025 05:20:52 - INFO - __main__ -   epoch 1 step 5200 loss 0.05197
03/25/2025 05:27:37 - INFO - __main__ -   epoch 1 step 5300 loss 0.05212
03/25/2025 05:34:21 - INFO - __main__ -   epoch 1 step 5400 loss 0.05332
03/25/2025 05:41:06 - INFO - __main__ -   epoch 1 step 5500 loss 0.05304
03/25/2025 05:41:42 - INFO - __main__ -   ***** Running evaluation *****
03/25/2025 05:41:42 - INFO - __main__ -     Num examples = 9604
03/25/2025 05:41:42 - INFO - __main__ -     Batch size = 64
03/25/2025 05:48:48 - INFO - __main__ -     eval_loss = 1.212
03/25/2025 05:48:48 - INFO - __main__ -     eval_mrr = 0.41
03/25/2025 05:54:56 - INFO - __main__ -   epoch 1 step 5600 loss 0.04328
03/25/2025 06:01:41 - INFO - __main__ -   epoch 1 step 5700 loss 0.04207
03/25/2025 06:08:25 - INFO - __main__ -   epoch 1 step 5800 loss 0.04321
03/25/2025 06:15:10 - INFO - __main__ -   epoch 1 step 5900 loss 0.04419
03/25/2025 06:21:54 - INFO - __main__ -   epoch 1 step 6000 loss 0.04809
03/25/2025 06:28:39 - INFO - __main__ -   epoch 1 step 6100 loss 0.04565
03/25/2025 06:35:23 - INFO - __main__ -   epoch 1 step 6200 loss 0.0474
03/25/2025 06:41:52 - INFO - __main__ -   ***** Running evaluation *****
03/25/2025 06:41:52 - INFO - __main__ -     Num examples = 9604
03/25/2025 06:41:52 - INFO - __main__ -     Batch size = 64
03/25/2025 06:48:58 - INFO - __main__ -     eval_loss = 1.1919
03/25/2025 06:48:58 - INFO - __main__ -     eval_mrr = 0.4172
03/25/2025 06:49:14 - INFO - __main__ -   epoch 1 step 6300 loss 0.01576
03/25/2025 06:55:59 - INFO - __main__ -   epoch 1 step 6400 loss 0.0455
03/25/2025 07:02:43 - INFO - __main__ -   epoch 1 step 6500 loss 0.04069
03/25/2025 07:09:28 - INFO - __main__ -   epoch 1 step 6600 loss 0.04801
03/25/2025 07:16:12 - INFO - __main__ -   epoch 1 step 6700 loss 0.04757
03/25/2025 07:22:57 - INFO - __main__ -   epoch 1 step 6800 loss 0.04524
03/25/2025 07:29:42 - INFO - __main__ -   epoch 1 step 6900 loss 0.04504
03/25/2025 07:36:26 - INFO - __main__ -   epoch 1 step 7000 loss 0.04556
03/25/2025 07:42:02 - INFO - __main__ -   ***** Running evaluation *****
03/25/2025 07:42:02 - INFO - __main__ -     Num examples = 9604
03/25/2025 07:42:02 - INFO - __main__ -     Batch size = 64
03/25/2025 07:49:08 - INFO - __main__ -     eval_loss = 1.1259
03/25/2025 07:49:08 - INFO - __main__ -     eval_mrr = 0.4261
03/25/2025 07:49:08 - INFO - __main__ -     ********************
03/25/2025 07:49:08 - INFO - __main__ -     Best mrr:0.4261
03/25/2025 07:49:08 - INFO - __main__ -     ********************
03/25/2025 07:49:09 - INFO - __main__ -   Saving model checkpoint to ./saved_models_graph/checkpoint-best-mrr/model.bin
03/25/2025 07:50:18 - INFO - __main__ -   epoch 1 step 7100 loss 0.03229
03/25/2025 07:57:02 - INFO - __main__ -   epoch 1 step 7200 loss 0.04632
03/25/2025 08:03:46 - INFO - __main__ -   epoch 1 step 7300 loss 0.05123
03/25/2025 08:10:31 - INFO - __main__ -   epoch 1 step 7400 loss 0.04925
03/25/2025 08:17:15 - INFO - __main__ -   epoch 1 step 7500 loss 0.04826
03/25/2025 08:24:00 - INFO - __main__ -   epoch 1 step 7600 loss 0.04763
03/25/2025 08:30:44 - INFO - __main__ -   epoch 1 step 7700 loss 0.04885
03/25/2025 08:37:29 - INFO - __main__ -   epoch 1 step 7800 loss 0.05103
03/25/2025 08:42:10 - INFO - __main__ -   ***** Running evaluation *****
03/25/2025 08:42:10 - INFO - __main__ -     Num examples = 9604
03/25/2025 08:42:10 - INFO - __main__ -     Batch size = 64
03/25/2025 08:49:16 - INFO - __main__ -     eval_loss = 1.1138
03/25/2025 08:49:16 - INFO - __main__ -     eval_mrr = 0.4268
03/25/2025 08:49:16 - INFO - __main__ -     ********************
03/25/2025 08:49:16 - INFO - __main__ -     Best mrr:0.4268
03/25/2025 08:49:16 - INFO - __main__ -     ********************
03/25/2025 08:49:18 - INFO - __main__ -   Saving model checkpoint to ./saved_models_graph/checkpoint-best-mrr/model.bin
