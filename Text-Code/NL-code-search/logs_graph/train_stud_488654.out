05/22/2025 21:45:38 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/22/2025 21:45:38 - DEBUG - urllib3.connectionpool -   Starting new HTTPS connection (1): huggingface.co:443
05/22/2025 21:45:38 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /microsoft/graphcodebert-base/resolve/main/config.json HTTP/11" 200 0
05/22/2025 21:45:38 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /roberta-base/resolve/main/tokenizer_config.json HTTP/11" 200 0
05/22/2025 21:45:39 - INFO - __main__ -   ************ Load Teacher Model ***************
05/22/2025 21:45:39 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /microsoft/graphcodebert-base/resolve/main/config.json HTTP/11" 200 0
05/22/2025 21:45:39 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /microsoft/graphcodebert-base/resolve/main/model.safetensors HTTP/11" 404 0
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/22/2025 21:45:43 - INFO - __main__ -   ************ Load Student Model ***************
05/22/2025 21:45:43 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../dataset/train_stud.jsonl', output_dir='./saved_models_distil_graph_compress', eval_data_file='../dataset/valid.jsonl', test_data_file='../dataset/test.jsonl', model_type='roberta', model_name_or_path='microsoft/graphcodebert-base', mlm=False, mlm_probability=0.15, config_name='microsoft/graphcodebert-base', tokenizer_name='roberta-base', cache_dir='', block_size=400, do_train=True, do_eval=True, do_test=False, evaluate_during_training=True, do_lower_case=False, train_batch_size=16, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=123456, epoch=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', teacher_name_or_path='microsoft/graphcodebert-base', quantize=False, quantize4=False, quantizef8=False, prune=False, prune4=False, prune6=False, job_id=None, attention_heads=8, hidden_dim=96, intermediate_size=64, n_layers=12, vocab_size=1000, n_gpu=1, device=device(type='cuda'), per_gpu_train_batch_size=16, per_gpu_eval_batch_size=64, start_epoch=0, start_step=0)
05/22/2025 21:47:59 - INFO - __main__ -   *** Example ***
05/22/2025 21:47:59 - INFO - __main__ -   idx: 0
05/22/2025 21:47:59 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_write', '_(', '_self', '_,', '_p', 'kt', '_)', '_:', '_if', '_is', 'instance', '_(', '_p', 'kt', '_,', '_bytes', '_)', '_:', '_if', '_not', '_self', '_.', '_header', '_', 'present', '_:', '_self', '_.', '__', 'write', '_', 'header', '_(', '_p', 'kt', '_)', '_self', '_.', '__', 'write', '_', 'pack', 'et', '_(', '_p', 'kt', '_)', '_else', '_:', '_p', 'kt', '_=', '_p', 'kt', '_.', '___', 'iter', '__', '_(', '_)', '_for', '_p', '_in', '_p', 'kt', '_:', '_if', '_not', '_self', '_.', '_header', '_', 'present', '_:', '_self', '_.', '__', 'write', '_', 'header', '_(', '_p', '_)', '_self', '_.', '__', 'write', '_', 'pack', 'et', '_(', '_p', '_)', '</s>']
05/22/2025 21:47:59 - INFO - __main__ -   code_ids: 0 9232 3116 36 1403 2156 181 7282 4839 4832 114 16 48768 36 181 7282 2156 46487 4839 4832 114 45 1403 479 12734 1215 25870 4832 1403 479 18134 29631 1215 24419 36 181 7282 4839 1403 479 18134 29631 1215 12486 594 36 181 7282 4839 1493 4832 181 7282 5457 181 7282 479 27148 8660 30529 36 4839 13 181 11 181 7282 4832 114 45 1403 479 12734 1215 25870 4832 1403 479 18134 29631 1215 24419 36 181 4839 1403 479 18134 29631 1215 12486 594 36 181 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
05/22/2025 21:47:59 - INFO - __main__ -   nl_tokens: ['<s>', 'Writ', 'es', '_a', '_Pack', 'et', '_or', '_bytes', '_to', '_a', '_p', 'cap', '_file', '_.', '</s>']
05/22/2025 21:47:59 - INFO - __main__ -   nl_ids: 0 45987 293 10 8898 594 50 46487 7 10 181 10906 2870 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
05/22/2025 21:47:59 - INFO - __main__ -   *** Example ***
05/22/2025 21:47:59 - INFO - __main__ -   idx: 1
05/22/2025 21:47:59 - INFO - __main__ -   code_tokens: ['<s>', 'def', '__', 'write', '_', 'pack', 'et', '_(', '_self', '_,', '_packet', '_,', '_sec', '_=', '_None', '_,', '_use', 'c', '_=', '_None', '_,', '_ca', 'pl', 'en', '_=', '_None', '_,', '_wire', 'len', '_=', '_None', '_)', '_:', '_if', '_has', 'attr', '_(', '_packet', '_,', '_"', 'time', '"', '_)', '_:', '_if', '_sec', '_is', '_None', '_:', '_sec', '_=', '_int', '_(', '_packet', '_.', '_time', '_)', '_use', 'c', '_=', '_int', '_(', '_round', '_(', '_(', '_packet', '_.', '_time', '_-', '_sec', '_)', '_*', '_(', '_100', '0000000', '_if', '_self', '_.', '_nano', '_else', '_100', '0000', '_)', '_)', '_)', '_if', '_use', 'c', '_is', '_None', '_:', '_use', 'c', '_=', '_0', '_raw', 'p', 'kt', '_=', '_raw', '_(', '_packet', '_)', '_ca', 'pl', 'en', '_=', '_len', '_(', '_raw', 'p', 'kt', '_)', '_if', '_ca', 'pl', 'en', '_is', '_None', '_else', '_ca', 'pl', 'en', '_if', '_wire', 'len', '_is', '_None', '_:', '_if', '_has', 'attr', '_(', '_packet', '_,', '_"', 'wire', 'len', '"', '_)', '_:', '_wire', 'len', '_=', '_packet', '_.', '_wire', 'len', '_if', '_wire', 'len', '_is', '_None', '_:', '_wire', 'len', '_=', '_ca', 'pl', 'en', '_Raw', 'P', 'cap', 'Writer', '_.', '__', 'write', '_', 'pack', 'et', '_(', '_self', '_,', '_raw', 'p', 'kt', '_,', '_sec', '_=', '_sec', '_,', '_use', 'c', '_=', '_use', 'c', '_,', '_ca', 'pl', 'en', '_=', '_ca', 'pl', 'en', '_,', '_wire', 'len', '_=', '_wire', 'len', '_)', '</s>']
05/22/2025 21:47:59 - INFO - __main__ -   code_ids: 0 9232 18134 29631 1215 12486 594 36 1403 2156 29635 2156 15636 5457 9291 2156 304 438 5457 9291 2156 6056 2911 225 5457 9291 2156 8869 8476 5457 9291 4839 4832 114 34 44156 36 29635 2156 22 958 113 4839 4832 114 15636 16 9291 4832 15636 5457 6979 36 29635 479 86 4839 304 438 5457 6979 36 1062 36 36 29635 479 86 111 15636 4839 1009 36 727 45121 114 1403 479 36924 1493 727 14200 4839 4839 4839 114 304 438 16 9291 4832 304 438 5457 321 6087 642 7282 5457 6087 36 29635 4839 6056 2911 225 5457 25528 36 6087 642 7282 4839 114 6056 2911 225 16 9291 1493 6056 2911 225 114 8869 8476 16 9291 4832 114 34 44156 36 29635 2156 22 11208 8476 113 4839 4832 8869 8476 5457 29635 479 8869 8476 114 8869 8476 16 9291 4832 8869 8476 5457 6056 2911 225 8214 510 10906 45489 479 18134 29631 1215 12486 594 36 1403 2156 6087 642 7282 2156 15636 5457 15636 2156 304 438 5457 304 438 2156 6056 2911 225 5457 6056 2911 225 2156 8869 8476 5457 8869 8476 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
05/22/2025 21:47:59 - INFO - __main__ -   nl_tokens: ['<s>', 'Writ', 'es', '_a', '_single', '_packet', '_to', '_the', '_p', 'cap', '_file', '_.', '</s>']
05/22/2025 21:47:59 - INFO - __main__ -   nl_ids: 0 45987 293 10 881 29635 7 5 181 10906 2870 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
05/22/2025 21:47:59 - INFO - __main__ -   *** Example ***
05/22/2025 21:47:59 - INFO - __main__ -   idx: 2
05/22/2025 21:47:59 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_vo', 'ip', '_', 'play', '_(', '_s', '1', '_,', '_l', 'st', '_=', '_None', '_,', '_*', '_*', '_k', 'args', '_)', '_:', '_d', 'sp', '_,', '_r', 'd', '_=', '_os', '_.', '_pop', 'en', '2', '_(', '_so', 'x', '_', 'base', '_%', '_""', '_)', '_def', '_play', '_(', '_p', 'kt', '_)', '_:', '_if', '_not', '_p', 'kt', '_:', '_return', '_if', '_not', '_p', 'kt', '_.', '_has', 'layer', '_(', '_UDP', '_)', '_or', '_not', '_p', 'kt', '_.', '_has', 'layer', '_(', '_IP', '_)', '_:', '_return', '_ip', '_=', '_p', 'kt', '_.', '_get', 'layer', '_(', '_IP', '_)', '_if', '_s', '1', '_==', '_ip', '_.', '_src', '_:', '_d', 'sp', '_.', '_write', '_(', '_p', 'kt', '_.', '_get', 'layer', '_(', '_conf', '_.', '_raw', '_', 'layer', '_)', '_.', '_load', '_[', '_12', '_:', '_]', '_)', '_try', '_:', '_if', '_l', 'st', '_is', '_None', '_:', '_sniff', '_(', '_store', '_=', '_0', '_,', '_pr', 'n', '_=', '_play', '_,', '_*', '_*', '_k', 'args', '_)', '_else', '_:', '_for', '_p', '_in', '_l', 'st', '_:', '_play', '_(', '_p', '_)', '_finally', '_:', '_d', 'sp', '_.', '_close', '_(', '_)', '_r', 'd', '_.', '_close', '_(', '_)', '</s>']
05/22/2025 21:47:59 - INFO - __main__ -   code_ids: 0 9232 17377 1588 1215 5785 36 579 134 2156 784 620 5457 9291 2156 1009 1009 449 48204 4839 4832 385 4182 2156 910 417 5457 11988 479 3495 225 176 36 98 1178 1215 11070 7606 41039 4839 3816 310 36 181 7282 4839 4832 114 45 181 7282 4832 671 114 45 181 7282 479 34 39165 36 46397 4839 50 45 181 7282 479 34 39165 36 6442 4839 4832 671 36180 5457 181 7282 479 120 39165 36 6442 4839 114 579 134 45994 36180 479 47215 4832 385 4182 479 3116 36 181 7282 479 120 39165 36 7856 479 6087 1215 39165 4839 479 7511 646 316 4832 27779 4839 860 4832 114 784 620 16 9291 4832 25275 36 1400 5457 321 2156 3349 282 5457 310 2156 1009 1009 449 48204 4839 1493 4832 13 181 11 784 620 4832 310 36 181 4839 1747 4832 385 4182 479 593 36 4839 910 417 479 593 36 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
05/22/2025 21:47:59 - INFO - __main__ -   nl_tokens: ['<s>', 'Play', '_Vo', 'IP', '_packets', '_with', '_RAW', '_data', '_that', '_are', '_either', '_sniff', 'ed', '_either', '_from', '_an', '_IP', '_or', '_specified', '_as', '_a', '_list', '_.', '</s>']
05/22/2025 21:47:59 - INFO - __main__ -   nl_ids: 0 20780 18270 3808 30781 19 23112 414 14 32 1169 25275 196 1169 31 41 6442 50 17966 25 10 889 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
05/22/2025 21:48:09 - INFO - __main__ -   ***** Running training *****
05/22/2025 21:48:09 - INFO - __main__ -     Num examples = 125910
05/22/2025 21:48:09 - INFO - __main__ -     Num Epochs = 2
05/22/2025 21:48:09 - INFO - __main__ -     Instantaneous batch size per GPU = 16
05/22/2025 21:48:09 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16
05/22/2025 21:48:09 - INFO - __main__ -     Gradient Accumulation steps = 1
05/22/2025 21:48:09 - INFO - __main__ -     Total optimization steps = 15740
05/22/2025 21:50:27 - INFO - __main__ -   epoch 0 step 100 loss 0.97622
05/22/2025 21:52:41 - INFO - __main__ -   epoch 0 step 200 loss 0.97689
05/22/2025 21:54:56 - INFO - __main__ -   epoch 0 step 300 loss 0.96859
05/22/2025 21:57:10 - INFO - __main__ -   epoch 0 step 400 loss 0.97666
05/22/2025 21:59:24 - INFO - __main__ -   epoch 0 step 500 loss 0.97883
05/22/2025 22:01:39 - INFO - __main__ -   epoch 0 step 600 loss 0.97887
05/22/2025 22:03:53 - INFO - __main__ -   epoch 0 step 700 loss 0.98086
05/22/2025 22:06:02 - INFO - __main__ -   ***** Running evaluation *****
05/22/2025 22:06:02 - INFO - __main__ -     Num examples = 9604
05/22/2025 22:06:02 - INFO - __main__ -     Batch size = 64
05/22/2025 22:07:44 - INFO - __main__ -     eval_loss = 4.1405
05/22/2025 22:07:44 - INFO - __main__ -     eval_mrr = 0.001
05/22/2025 22:07:44 - INFO - __main__ -     ********************
05/22/2025 22:07:44 - INFO - __main__ -     Best mrr:0.001
05/22/2025 22:07:44 - INFO - __main__ -     ********************
05/22/2025 22:07:45 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/22/2025 22:08:02 - INFO - __main__ -   epoch 0 step 800 loss 1.00306
05/22/2025 22:10:16 - INFO - __main__ -   epoch 0 step 900 loss 0.98558
05/22/2025 22:12:31 - INFO - __main__ -   epoch 0 step 1000 loss 0.99713
05/22/2025 22:14:45 - INFO - __main__ -   epoch 0 step 1100 loss 1.00016
05/22/2025 22:16:59 - INFO - __main__ -   epoch 0 step 1200 loss 1.00179
05/22/2025 22:19:14 - INFO - __main__ -   epoch 0 step 1300 loss 1.00153
05/22/2025 22:21:28 - INFO - __main__ -   epoch 0 step 1400 loss 0.99652
05/22/2025 22:23:42 - INFO - __main__ -   epoch 0 step 1500 loss 0.99201
05/22/2025 22:25:21 - INFO - __main__ -   ***** Running evaluation *****
05/22/2025 22:25:21 - INFO - __main__ -     Num examples = 9604
05/22/2025 22:25:21 - INFO - __main__ -     Batch size = 64
05/22/2025 22:27:04 - INFO - __main__ -     eval_loss = 4.1405
05/22/2025 22:27:04 - INFO - __main__ -     eval_mrr = 0.001
05/22/2025 22:27:39 - INFO - __main__ -   epoch 0 step 1600 loss 1.02718
05/22/2025 22:29:53 - INFO - __main__ -   epoch 0 step 1700 loss 0.98883
05/22/2025 22:32:07 - INFO - __main__ -   epoch 0 step 1800 loss 0.9892
05/22/2025 22:34:22 - INFO - __main__ -   epoch 0 step 1900 loss 0.98626
05/22/2025 22:36:36 - INFO - __main__ -   epoch 0 step 2000 loss 0.98743
05/22/2025 22:38:50 - INFO - __main__ -   epoch 0 step 2100 loss 0.98943
05/22/2025 22:41:04 - INFO - __main__ -   epoch 0 step 2200 loss 0.98687
05/22/2025 22:43:19 - INFO - __main__ -   epoch 0 step 2300 loss 0.98681
05/22/2025 22:44:40 - INFO - __main__ -   ***** Running evaluation *****
05/22/2025 22:44:40 - INFO - __main__ -     Num examples = 9604
05/22/2025 22:44:40 - INFO - __main__ -     Batch size = 64
05/22/2025 22:46:22 - INFO - __main__ -     eval_loss = 4.1405
05/22/2025 22:46:22 - INFO - __main__ -     eval_mrr = 0.001
05/22/2025 22:47:15 - INFO - __main__ -   epoch 0 step 2400 loss 1.00874
05/22/2025 22:49:29 - INFO - __main__ -   epoch 0 step 2500 loss 0.99397
05/22/2025 22:51:44 - INFO - __main__ -   epoch 0 step 2600 loss 0.99228
05/22/2025 22:53:58 - INFO - __main__ -   epoch 0 step 2700 loss 0.98938
05/22/2025 22:56:12 - INFO - __main__ -   epoch 0 step 2800 loss 0.9886
05/22/2025 22:58:27 - INFO - __main__ -   epoch 0 step 2900 loss 0.99073
05/22/2025 23:00:41 - INFO - __main__ -   epoch 0 step 3000 loss 0.99118
05/22/2025 23:02:55 - INFO - __main__ -   epoch 0 step 3100 loss 0.9928
05/22/2025 23:04:00 - INFO - __main__ -   ***** Running evaluation *****
05/22/2025 23:04:00 - INFO - __main__ -     Num examples = 9604
05/22/2025 23:04:00 - INFO - __main__ -     Batch size = 64
05/22/2025 23:05:42 - INFO - __main__ -     eval_loss = 4.1405
05/22/2025 23:05:42 - INFO - __main__ -     eval_mrr = 0.001
05/22/2025 23:06:52 - INFO - __main__ -   epoch 0 step 3200 loss 0.99906
05/22/2025 23:09:06 - INFO - __main__ -   epoch 0 step 3300 loss 0.99506
05/22/2025 23:11:20 - INFO - __main__ -   epoch 0 step 3400 loss 0.98156
05/22/2025 23:13:34 - INFO - __main__ -   epoch 0 step 3500 loss 0.98686
05/22/2025 23:15:49 - INFO - __main__ -   epoch 0 step 3600 loss 0.99137
05/22/2025 23:18:03 - INFO - __main__ -   epoch 0 step 3700 loss 0.99303
05/22/2025 23:20:18 - INFO - __main__ -   epoch 0 step 3800 loss 0.99415
05/22/2025 23:22:32 - INFO - __main__ -   epoch 0 step 3900 loss 0.99108
05/22/2025 23:23:19 - INFO - __main__ -   ***** Running evaluation *****
05/22/2025 23:23:19 - INFO - __main__ -     Num examples = 9604
05/22/2025 23:23:19 - INFO - __main__ -     Batch size = 64
05/22/2025 23:25:01 - INFO - __main__ -     eval_loss = 4.1405
05/22/2025 23:25:01 - INFO - __main__ -     eval_mrr = 0.001
05/22/2025 23:26:29 - INFO - __main__ -   epoch 0 step 4000 loss 1.00117
05/22/2025 23:28:43 - INFO - __main__ -   epoch 0 step 4100 loss 1.00428
05/22/2025 23:30:58 - INFO - __main__ -   epoch 0 step 4200 loss 1.00312
05/22/2025 23:33:12 - INFO - __main__ -   epoch 0 step 4300 loss 1.00066
05/22/2025 23:35:26 - INFO - __main__ -   epoch 0 step 4400 loss 0.99667
05/22/2025 23:37:41 - INFO - __main__ -   epoch 0 step 4500 loss 0.99205
05/22/2025 23:39:55 - INFO - __main__ -   epoch 0 step 4600 loss 0.99219
05/22/2025 23:42:09 - INFO - __main__ -   epoch 0 step 4700 loss 0.99027
05/22/2025 23:42:39 - INFO - __main__ -   ***** Running evaluation *****
05/22/2025 23:42:39 - INFO - __main__ -     Num examples = 9604
05/22/2025 23:42:39 - INFO - __main__ -     Batch size = 64
05/22/2025 23:44:21 - INFO - __main__ -     eval_loss = 4.1405
05/22/2025 23:44:21 - INFO - __main__ -     eval_mrr = 0.001
05/22/2025 23:46:06 - INFO - __main__ -   epoch 0 step 4800 loss 0.96305
05/22/2025 23:48:20 - INFO - __main__ -   epoch 0 step 4900 loss 0.979
05/22/2025 23:50:35 - INFO - __main__ -   epoch 0 step 5000 loss 0.98384
05/22/2025 23:52:49 - INFO - __main__ -   epoch 0 step 5100 loss 0.98963
05/22/2025 23:55:03 - INFO - __main__ -   epoch 0 step 5200 loss 0.98341
05/22/2025 23:57:17 - INFO - __main__ -   epoch 0 step 5300 loss 0.97786
05/22/2025 23:59:32 - INFO - __main__ -   epoch 0 step 5400 loss 0.98064
05/23/2025 00:01:46 - INFO - __main__ -   epoch 0 step 5500 loss 0.983
05/23/2025 00:01:58 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 00:01:58 - INFO - __main__ -     Num examples = 9604
05/23/2025 00:01:58 - INFO - __main__ -     Batch size = 64
05/23/2025 00:03:40 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 00:03:40 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 00:05:43 - INFO - __main__ -   epoch 0 step 5600 loss 0.96789
05/23/2025 00:07:57 - INFO - __main__ -   epoch 0 step 5700 loss 0.97093
05/23/2025 00:10:11 - INFO - __main__ -   epoch 0 step 5800 loss 0.97971
05/23/2025 00:12:25 - INFO - __main__ -   epoch 0 step 5900 loss 0.98341
05/23/2025 00:14:40 - INFO - __main__ -   epoch 0 step 6000 loss 0.98311
05/23/2025 00:16:54 - INFO - __main__ -   epoch 0 step 6100 loss 0.98372
05/23/2025 00:19:08 - INFO - __main__ -   epoch 0 step 6200 loss 0.9875
05/23/2025 00:21:17 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 00:21:17 - INFO - __main__ -     Num examples = 9604
05/23/2025 00:21:17 - INFO - __main__ -     Batch size = 64
05/23/2025 00:23:00 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 00:23:00 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 00:23:05 - INFO - __main__ -   epoch 0 step 6300 loss 0.93735
05/23/2025 00:25:19 - INFO - __main__ -   epoch 0 step 6400 loss 0.97345
05/23/2025 00:27:34 - INFO - __main__ -   epoch 0 step 6500 loss 0.97402
05/23/2025 00:29:48 - INFO - __main__ -   epoch 0 step 6600 loss 0.97899
05/23/2025 00:32:02 - INFO - __main__ -   epoch 0 step 6700 loss 0.98147
05/23/2025 00:34:17 - INFO - __main__ -   epoch 0 step 6800 loss 0.98462
05/23/2025 00:36:31 - INFO - __main__ -   epoch 0 step 6900 loss 0.98659
05/23/2025 00:38:45 - INFO - __main__ -   epoch 0 step 7000 loss 0.98959
05/23/2025 00:40:37 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 00:40:37 - INFO - __main__ -     Num examples = 9604
05/23/2025 00:40:37 - INFO - __main__ -     Batch size = 64
05/23/2025 00:42:19 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 00:42:19 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 00:42:42 - INFO - __main__ -   epoch 0 step 7100 loss 0.92624
05/23/2025 00:44:56 - INFO - __main__ -   epoch 0 step 7200 loss 0.98061
05/23/2025 00:47:10 - INFO - __main__ -   epoch 0 step 7300 loss 0.98555
05/23/2025 00:49:25 - INFO - __main__ -   epoch 0 step 7400 loss 0.98383
05/23/2025 00:51:39 - INFO - __main__ -   epoch 0 step 7500 loss 0.98101
05/23/2025 00:53:54 - INFO - __main__ -   epoch 0 step 7600 loss 0.97918
05/23/2025 00:56:08 - INFO - __main__ -   epoch 0 step 7700 loss 0.98023
05/23/2025 00:58:22 - INFO - __main__ -   epoch 0 step 7800 loss 0.98536
05/23/2025 00:59:56 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 00:59:56 - INFO - __main__ -     Num examples = 9604
05/23/2025 00:59:56 - INFO - __main__ -     Batch size = 64
05/23/2025 01:01:38 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 01:01:38 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 01:03:53 - INFO - __main__ -   epoch 1 step 100 loss 0.97089
05/23/2025 01:06:07 - INFO - __main__ -   epoch 1 step 200 loss 0.97345
05/23/2025 01:08:22 - INFO - __main__ -   epoch 1 step 300 loss 0.97722
05/23/2025 01:10:36 - INFO - __main__ -   epoch 1 step 400 loss 0.97459
05/23/2025 01:12:51 - INFO - __main__ -   epoch 1 step 500 loss 0.97578
05/23/2025 01:15:05 - INFO - __main__ -   epoch 1 step 600 loss 0.97799
05/23/2025 01:17:20 - INFO - __main__ -   epoch 1 step 700 loss 0.97566
05/23/2025 01:19:17 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 01:19:17 - INFO - __main__ -     Num examples = 9604
05/23/2025 01:19:17 - INFO - __main__ -     Batch size = 64
05/23/2025 01:20:59 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 01:20:59 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 01:21:16 - INFO - __main__ -   epoch 1 step 800 loss 1.02292
05/23/2025 01:23:31 - INFO - __main__ -   epoch 1 step 900 loss 0.9826
05/23/2025 01:25:45 - INFO - __main__ -   epoch 1 step 1000 loss 0.97872
05/23/2025 01:28:00 - INFO - __main__ -   epoch 1 step 1100 loss 0.97881
05/23/2025 01:30:14 - INFO - __main__ -   epoch 1 step 1200 loss 0.97692
05/23/2025 01:32:28 - INFO - __main__ -   epoch 1 step 1300 loss 0.97826
05/23/2025 01:34:43 - INFO - __main__ -   epoch 1 step 1400 loss 0.97744
05/23/2025 01:36:57 - INFO - __main__ -   epoch 1 step 1500 loss 0.97989
05/23/2025 01:38:36 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 01:38:36 - INFO - __main__ -     Num examples = 9604
05/23/2025 01:38:36 - INFO - __main__ -     Batch size = 64
05/23/2025 01:40:18 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 01:40:18 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 01:40:53 - INFO - __main__ -   epoch 1 step 1600 loss 1.02667
05/23/2025 01:43:08 - INFO - __main__ -   epoch 1 step 1700 loss 0.99341
05/23/2025 01:45:22 - INFO - __main__ -   epoch 1 step 1800 loss 0.98943
05/23/2025 01:47:36 - INFO - __main__ -   epoch 1 step 1900 loss 0.99528
05/23/2025 01:49:51 - INFO - __main__ -   epoch 1 step 2000 loss 0.99719
05/23/2025 01:52:05 - INFO - __main__ -   epoch 1 step 2100 loss 0.99351
05/23/2025 01:54:19 - INFO - __main__ -   epoch 1 step 2200 loss 0.99458
05/23/2025 01:56:34 - INFO - __main__ -   epoch 1 step 2300 loss 0.99365
05/23/2025 01:57:55 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 01:57:55 - INFO - __main__ -     Num examples = 9604
05/23/2025 01:57:55 - INFO - __main__ -     Batch size = 64
05/23/2025 01:59:37 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 01:59:37 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 02:00:30 - INFO - __main__ -   epoch 1 step 2400 loss 1.0008
05/23/2025 02:02:44 - INFO - __main__ -   epoch 1 step 2500 loss 1.01307
05/23/2025 02:04:58 - INFO - __main__ -   epoch 1 step 2600 loss 1.00161
05/23/2025 02:07:13 - INFO - __main__ -   epoch 1 step 2700 loss 0.99987
05/23/2025 02:09:27 - INFO - __main__ -   epoch 1 step 2800 loss 0.99899
05/23/2025 02:11:42 - INFO - __main__ -   epoch 1 step 2900 loss 0.99624
05/23/2025 02:13:56 - INFO - __main__ -   epoch 1 step 3000 loss 0.99881
05/23/2025 02:16:10 - INFO - __main__ -   epoch 1 step 3100 loss 0.99941
05/23/2025 02:17:15 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 02:17:15 - INFO - __main__ -     Num examples = 9604
05/23/2025 02:17:15 - INFO - __main__ -     Batch size = 64
05/23/2025 02:18:57 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 02:18:57 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 02:20:07 - INFO - __main__ -   epoch 1 step 3200 loss 0.9966
05/23/2025 02:22:21 - INFO - __main__ -   epoch 1 step 3300 loss 1.00056
05/23/2025 02:24:36 - INFO - __main__ -   epoch 1 step 3400 loss 0.98988
05/23/2025 02:26:50 - INFO - __main__ -   epoch 1 step 3500 loss 0.9943
05/23/2025 02:29:04 - INFO - __main__ -   epoch 1 step 3600 loss 0.98801
05/23/2025 02:31:19 - INFO - __main__ -   epoch 1 step 3700 loss 0.98225
05/23/2025 02:33:33 - INFO - __main__ -   epoch 1 step 3800 loss 0.98568
05/23/2025 02:35:48 - INFO - __main__ -   epoch 1 step 3900 loss 0.9866
05/23/2025 02:36:35 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 02:36:35 - INFO - __main__ -     Num examples = 9604
05/23/2025 02:36:35 - INFO - __main__ -     Batch size = 64
05/23/2025 02:38:17 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 02:38:17 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 02:39:44 - INFO - __main__ -   epoch 1 step 4000 loss 0.95643
05/23/2025 02:41:58 - INFO - __main__ -   epoch 1 step 4100 loss 0.97806
05/23/2025 02:44:13 - INFO - __main__ -   epoch 1 step 4200 loss 0.98357
05/23/2025 02:46:27 - INFO - __main__ -   epoch 1 step 4300 loss 0.98836
05/23/2025 02:48:41 - INFO - __main__ -   epoch 1 step 4400 loss 0.99191
05/23/2025 02:50:56 - INFO - __main__ -   epoch 1 step 4500 loss 0.99452
05/23/2025 02:53:10 - INFO - __main__ -   epoch 1 step 4600 loss 0.99009
05/23/2025 02:55:24 - INFO - __main__ -   epoch 1 step 4700 loss 0.99379
05/23/2025 02:55:54 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 02:55:54 - INFO - __main__ -     Num examples = 9604
05/23/2025 02:55:54 - INFO - __main__ -     Batch size = 64
05/23/2025 02:57:36 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 02:57:36 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 02:59:21 - INFO - __main__ -   epoch 1 step 4800 loss 0.95997
05/23/2025 03:01:35 - INFO - __main__ -   epoch 1 step 4900 loss 0.97613
05/23/2025 03:03:49 - INFO - __main__ -   epoch 1 step 5000 loss 0.99112
05/23/2025 03:06:04 - INFO - __main__ -   epoch 1 step 5100 loss 0.98968
05/23/2025 03:08:18 - INFO - __main__ -   epoch 1 step 5200 loss 0.99111
05/23/2025 03:10:33 - INFO - __main__ -   epoch 1 step 5300 loss 0.99232
05/23/2025 03:12:47 - INFO - __main__ -   epoch 1 step 5400 loss 0.9882
05/23/2025 03:15:01 - INFO - __main__ -   epoch 1 step 5500 loss 0.98861
05/23/2025 03:15:14 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 03:15:14 - INFO - __main__ -     Num examples = 9604
05/23/2025 03:15:14 - INFO - __main__ -     Batch size = 64
05/23/2025 03:16:56 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 03:16:56 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 03:18:58 - INFO - __main__ -   epoch 1 step 5600 loss 0.97088
05/23/2025 03:21:12 - INFO - __main__ -   epoch 1 step 5700 loss 0.98559
05/23/2025 03:23:27 - INFO - __main__ -   epoch 1 step 5800 loss 0.98589
05/23/2025 03:25:41 - INFO - __main__ -   epoch 1 step 5900 loss 0.98415
05/23/2025 03:27:56 - INFO - __main__ -   epoch 1 step 6000 loss 0.97919
05/23/2025 03:30:10 - INFO - __main__ -   epoch 1 step 6100 loss 0.97856
05/23/2025 03:32:24 - INFO - __main__ -   epoch 1 step 6200 loss 0.97618
05/23/2025 03:34:33 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 03:34:33 - INFO - __main__ -     Num examples = 9604
05/23/2025 03:34:33 - INFO - __main__ -     Batch size = 64
05/23/2025 03:36:15 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 03:36:15 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 03:36:21 - INFO - __main__ -   epoch 1 step 6300 loss 0.91981
05/23/2025 03:38:35 - INFO - __main__ -   epoch 1 step 6400 loss 0.9811
05/23/2025 03:40:50 - INFO - __main__ -   epoch 1 step 6500 loss 0.98748
05/23/2025 03:43:04 - INFO - __main__ -   epoch 1 step 6600 loss 0.98031
05/23/2025 03:45:19 - INFO - __main__ -   epoch 1 step 6700 loss 0.98423
05/23/2025 03:47:33 - INFO - __main__ -   epoch 1 step 6800 loss 0.98586
05/23/2025 03:49:47 - INFO - __main__ -   epoch 1 step 6900 loss 0.99163
05/23/2025 03:52:02 - INFO - __main__ -   epoch 1 step 7000 loss 0.99344
05/23/2025 03:53:53 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 03:53:53 - INFO - __main__ -     Num examples = 9604
05/23/2025 03:53:53 - INFO - __main__ -     Batch size = 64
05/23/2025 03:55:35 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 03:55:35 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 03:55:58 - INFO - __main__ -   epoch 1 step 7100 loss 0.97891
05/23/2025 03:58:12 - INFO - __main__ -   epoch 1 step 7200 loss 0.9786
05/23/2025 04:00:27 - INFO - __main__ -   epoch 1 step 7300 loss 0.97993
05/23/2025 04:02:41 - INFO - __main__ -   epoch 1 step 7400 loss 0.98606
05/23/2025 04:04:55 - INFO - __main__ -   epoch 1 step 7500 loss 0.98167
05/23/2025 04:07:09 - INFO - __main__ -   epoch 1 step 7600 loss 0.98186
05/23/2025 04:09:24 - INFO - __main__ -   epoch 1 step 7700 loss 0.98369
05/23/2025 04:11:38 - INFO - __main__ -   epoch 1 step 7800 loss 0.98449
05/23/2025 04:13:11 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 04:13:11 - INFO - __main__ -     Num examples = 9604
05/23/2025 04:13:11 - INFO - __main__ -     Batch size = 64
05/23/2025 04:14:53 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 04:14:53 - INFO - __main__ -     eval_mrr = 0.001
05/23/2025 04:14:54 - INFO - __main__ -   Size (MB): 22.0094
05/23/2025 04:14:54 - INFO - __main__ -   ***** Running evaluation *****
05/23/2025 04:14:54 - INFO - __main__ -     Num examples = 9604
05/23/2025 04:14:54 - INFO - __main__ -     Batch size = 64
05/23/2025 04:16:36 - INFO - __main__ -   ***** Eval results *****
05/23/2025 04:16:36 - INFO - __main__ -     eval_loss = 4.1405
05/23/2025 04:16:36 - INFO - __main__ -     eval_mrr = 0.001
