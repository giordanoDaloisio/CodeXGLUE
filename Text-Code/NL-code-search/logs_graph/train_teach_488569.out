05/20/2025 11:42:48 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
05/20/2025 11:42:48 - DEBUG - urllib3.connectionpool -   Starting new HTTPS connection (1): huggingface.co:443
05/20/2025 11:42:48 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /microsoft/graphcodebert-base/resolve/main/config.json HTTP/11" 200 0
05/20/2025 11:42:48 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /roberta-base/resolve/main/tokenizer_config.json HTTP/11" 200 0
05/20/2025 11:42:49 - DEBUG - urllib3.connectionpool -   https://huggingface.co:443 "HEAD /microsoft/graphcodebert-base/resolve/main/model.safetensors HTTP/11" 404 0
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/20/2025 11:42:53 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../dataset/train_teach.jsonl', output_dir='./saved_models_distil_graph_compress', eval_data_file='../dataset/valid.jsonl', test_data_file='../dataset/test.jsonl', model_type='roberta', model_name_or_path='microsoft/graphcodebert-base', mlm=False, mlm_probability=0.15, config_name='microsoft/graphcodebert-base', tokenizer_name='roberta-base', cache_dir='', block_size=256, do_train=True, do_eval=False, do_test=False, evaluate_during_training=True, do_lower_case=False, train_batch_size=32, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=123456, epoch=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', quantize=False, quantize4=False, quantizef8=False, prune=False, prune4=False, prune6=False, job_id=None, n_gpu=1, device=device(type='cuda'), per_gpu_train_batch_size=32, per_gpu_eval_batch_size=64, start_epoch=0, start_step=0)
05/20/2025 11:45:00 - INFO - __main__ -   *** Example ***
05/20/2025 11:45:00 - INFO - __main__ -   idx: 0
05/20/2025 11:45:00 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"', '__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_"', ';"', '_)', '_[', '_0', '_]', '</s>']
05/20/2025 11:45:00 - INFO - __main__ -   code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
05/20/2025 11:45:00 - INFO - __main__ -   nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']
05/20/2025 11:45:00 - INFO - __main__ -   nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
05/20/2025 11:45:00 - INFO - __main__ -   *** Example ***
05/20/2025 11:45:00 - INFO - __main__ -   idx: 1
05/20/2025 11:45:00 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."', '""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']
05/20/2025 11:45:00 - INFO - __main__ -   code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
05/20/2025 11:45:00 - INFO - __main__ -   nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
05/20/2025 11:45:00 - INFO - __main__ -   nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
05/20/2025 11:45:00 - INFO - __main__ -   *** Example ***
05/20/2025 11:45:00 - INFO - __main__ -   idx: 2
05/20/2025 11:45:00 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
05/20/2025 11:45:00 - INFO - __main__ -   code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
05/20/2025 11:45:00 - INFO - __main__ -   nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
05/20/2025 11:45:00 - INFO - __main__ -   nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/NFSHOME/gdaloisio/miniconda3/envs/codex/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
05/20/2025 11:45:06 - INFO - __main__ -   ***** Running training *****
05/20/2025 11:45:06 - INFO - __main__ -     Num examples = 125910
05/20/2025 11:45:06 - INFO - __main__ -     Num Epochs = 2
05/20/2025 11:45:06 - INFO - __main__ -     Instantaneous batch size per GPU = 32
05/20/2025 11:45:06 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
05/20/2025 11:45:06 - INFO - __main__ -     Gradient Accumulation steps = 1
05/20/2025 11:45:06 - INFO - __main__ -     Total optimization steps = 7870
05/20/2025 11:53:38 - INFO - __main__ -   epoch 0 step 100 loss 7.56227
05/20/2025 12:01:05 - INFO - __main__ -   epoch 0 step 200 loss 3.94956
05/20/2025 12:07:50 - INFO - __main__ -   epoch 0 step 300 loss 2.701
05/20/2025 12:14:16 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 12:14:16 - INFO - __main__ -     Num examples = 9604
05/20/2025 12:14:16 - INFO - __main__ -     Batch size = 64
05/20/2025 12:21:22 - INFO - __main__ -     eval_loss = 1.4286
05/20/2025 12:21:22 - INFO - __main__ -     eval_mrr = 0.3388
05/20/2025 12:21:22 - INFO - __main__ -     ********************
05/20/2025 12:21:22 - INFO - __main__ -     Best mrr:0.3388
05/20/2025 12:21:22 - INFO - __main__ -     ********************
05/20/2025 12:21:24 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 12:21:52 - INFO - __main__ -   epoch 0 step 400 loss 0.17059
05/20/2025 12:28:37 - INFO - __main__ -   epoch 0 step 500 loss 0.17021
05/20/2025 12:35:21 - INFO - __main__ -   epoch 0 step 600 loss 0.16725
05/20/2025 12:42:06 - INFO - __main__ -   epoch 0 step 700 loss 0.17304
05/20/2025 12:47:54 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 12:47:54 - INFO - __main__ -     Num examples = 9604
05/20/2025 12:47:54 - INFO - __main__ -     Batch size = 64
05/20/2025 12:55:00 - INFO - __main__ -     eval_loss = 1.4793
05/20/2025 12:55:00 - INFO - __main__ -     eval_mrr = 0.3295
05/20/2025 12:55:56 - INFO - __main__ -   epoch 0 step 800 loss 0.28039
05/20/2025 13:02:41 - INFO - __main__ -   epoch 0 step 900 loss 0.17977
05/20/2025 13:09:25 - INFO - __main__ -   epoch 0 step 1000 loss 0.19337
05/20/2025 13:16:10 - INFO - __main__ -   epoch 0 step 1100 loss 0.18658
05/20/2025 13:21:30 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 13:21:30 - INFO - __main__ -     Num examples = 9604
05/20/2025 13:21:30 - INFO - __main__ -     Batch size = 64
05/20/2025 13:28:36 - INFO - __main__ -     eval_loss = 1.1944
05/20/2025 13:28:36 - INFO - __main__ -     eval_mrr = 0.3407
05/20/2025 13:28:36 - INFO - __main__ -     ********************
05/20/2025 13:28:36 - INFO - __main__ -     Best mrr:0.3407
05/20/2025 13:28:36 - INFO - __main__ -     ********************
05/20/2025 13:28:38 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 13:30:03 - INFO - __main__ -   epoch 0 step 1200 loss 0.14494
05/20/2025 13:36:47 - INFO - __main__ -   epoch 0 step 1300 loss 0.18931
05/20/2025 13:43:32 - INFO - __main__ -   epoch 0 step 1400 loss 0.18355
05/20/2025 13:50:16 - INFO - __main__ -   epoch 0 step 1500 loss 0.17101
05/20/2025 13:55:08 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 13:55:08 - INFO - __main__ -     Num examples = 9604
05/20/2025 13:55:08 - INFO - __main__ -     Batch size = 64
05/20/2025 14:02:14 - INFO - __main__ -     eval_loss = 1.3538
05/20/2025 14:02:14 - INFO - __main__ -     eval_mrr = 0.3455
05/20/2025 14:02:14 - INFO - __main__ -     ********************
05/20/2025 14:02:14 - INFO - __main__ -     Best mrr:0.3455
05/20/2025 14:02:14 - INFO - __main__ -     ********************
05/20/2025 14:02:15 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 14:04:09 - INFO - __main__ -   epoch 0 step 1600 loss 0.11568
05/20/2025 14:10:53 - INFO - __main__ -   epoch 0 step 1700 loss 0.1535
05/20/2025 14:17:38 - INFO - __main__ -   epoch 0 step 1800 loss 0.15208
05/20/2025 14:24:23 - INFO - __main__ -   epoch 0 step 1900 loss 0.15423
05/20/2025 14:28:46 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 14:28:46 - INFO - __main__ -     Num examples = 9604
05/20/2025 14:28:46 - INFO - __main__ -     Batch size = 64
05/20/2025 14:35:52 - INFO - __main__ -     eval_loss = 1.3097
05/20/2025 14:35:52 - INFO - __main__ -     eval_mrr = 0.3229
05/20/2025 14:38:14 - INFO - __main__ -   epoch 0 step 2000 loss 0.18797
05/20/2025 14:44:58 - INFO - __main__ -   epoch 0 step 2100 loss 0.14861
05/20/2025 14:51:43 - INFO - __main__ -   epoch 0 step 2200 loss 0.15457
05/20/2025 14:58:28 - INFO - __main__ -   epoch 0 step 2300 loss 0.14827
05/20/2025 15:02:22 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 15:02:22 - INFO - __main__ -     Num examples = 9604
05/20/2025 15:02:22 - INFO - __main__ -     Batch size = 64
05/20/2025 15:09:29 - INFO - __main__ -     eval_loss = 1.3147
05/20/2025 15:09:29 - INFO - __main__ -     eval_mrr = 0.3498
05/20/2025 15:09:29 - INFO - __main__ -     ********************
05/20/2025 15:09:29 - INFO - __main__ -     Best mrr:0.3498
05/20/2025 15:09:29 - INFO - __main__ -     ********************
05/20/2025 15:09:31 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 15:12:21 - INFO - __main__ -   epoch 0 step 2400 loss 0.09188
05/20/2025 15:19:05 - INFO - __main__ -   epoch 0 step 2500 loss 0.13861
05/20/2025 15:25:50 - INFO - __main__ -   epoch 0 step 2600 loss 0.13842
05/20/2025 15:32:35 - INFO - __main__ -   epoch 0 step 2700 loss 0.1477
05/20/2025 15:36:01 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 15:36:01 - INFO - __main__ -     Num examples = 9604
05/20/2025 15:36:01 - INFO - __main__ -     Batch size = 64
05/20/2025 15:43:08 - INFO - __main__ -     eval_loss = 1.1562
05/20/2025 15:43:08 - INFO - __main__ -     eval_mrr = 0.3499
05/20/2025 15:43:08 - INFO - __main__ -     ********************
05/20/2025 15:43:08 - INFO - __main__ -     Best mrr:0.3499
05/20/2025 15:43:08 - INFO - __main__ -     ********************
05/20/2025 15:43:09 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 15:46:28 - INFO - __main__ -   epoch 0 step 2800 loss 0.14595
05/20/2025 15:53:13 - INFO - __main__ -   epoch 0 step 2900 loss 0.14838
05/20/2025 15:59:58 - INFO - __main__ -   epoch 0 step 3000 loss 0.14696
05/20/2025 16:06:42 - INFO - __main__ -   epoch 0 step 3100 loss 0.1474
05/20/2025 16:09:41 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 16:09:41 - INFO - __main__ -     Num examples = 9604
05/20/2025 16:09:41 - INFO - __main__ -     Batch size = 64
05/20/2025 16:16:47 - INFO - __main__ -     eval_loss = 1.1019
05/20/2025 16:16:47 - INFO - __main__ -     eval_mrr = 0.3638
05/20/2025 16:16:47 - INFO - __main__ -     ********************
05/20/2025 16:16:47 - INFO - __main__ -     Best mrr:0.3638
05/20/2025 16:16:47 - INFO - __main__ -     ********************
05/20/2025 16:16:49 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 16:20:35 - INFO - __main__ -   epoch 0 step 3200 loss 0.13416
05/20/2025 16:27:20 - INFO - __main__ -   epoch 0 step 3300 loss 0.13801
05/20/2025 16:34:05 - INFO - __main__ -   epoch 0 step 3400 loss 0.12741
05/20/2025 16:40:50 - INFO - __main__ -   epoch 0 step 3500 loss 0.12763
05/20/2025 16:43:19 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 16:43:19 - INFO - __main__ -     Num examples = 9604
05/20/2025 16:43:19 - INFO - __main__ -     Batch size = 64
05/20/2025 16:50:26 - INFO - __main__ -     eval_loss = 1.3557
05/20/2025 16:50:26 - INFO - __main__ -     eval_mrr = 0.3244
05/20/2025 16:54:41 - INFO - __main__ -   epoch 0 step 3600 loss 0.13601
05/20/2025 17:01:25 - INFO - __main__ -   epoch 0 step 3700 loss 0.13346
05/20/2025 17:08:10 - INFO - __main__ -   epoch 0 step 3800 loss 0.13121
05/20/2025 17:14:55 - INFO - __main__ -   epoch 0 step 3900 loss 0.12019
05/20/2025 17:16:57 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 17:16:57 - INFO - __main__ -     Num examples = 9604
05/20/2025 17:16:57 - INFO - __main__ -     Batch size = 64
05/20/2025 17:24:03 - INFO - __main__ -     eval_loss = 1.0387
05/20/2025 17:24:04 - INFO - __main__ -     eval_mrr = 0.3793
05/20/2025 17:24:04 - INFO - __main__ -     ********************
05/20/2025 17:24:04 - INFO - __main__ -     Best mrr:0.3793
05/20/2025 17:24:04 - INFO - __main__ -     ********************
05/20/2025 17:24:05 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 17:31:09 - INFO - __main__ -   epoch 1 step 100 loss 0.07344
05/20/2025 17:37:54 - INFO - __main__ -   epoch 1 step 200 loss 0.0705
05/20/2025 17:44:39 - INFO - __main__ -   epoch 1 step 300 loss 0.07013
05/20/2025 17:50:35 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 17:50:35 - INFO - __main__ -     Num examples = 9604
05/20/2025 17:50:35 - INFO - __main__ -     Batch size = 64
05/20/2025 17:57:42 - INFO - __main__ -     eval_loss = 1.2628
05/20/2025 17:57:42 - INFO - __main__ -     eval_mrr = 0.3781
05/20/2025 17:58:30 - INFO - __main__ -   epoch 1 step 400 loss 0.07812
05/20/2025 18:05:15 - INFO - __main__ -   epoch 1 step 500 loss 0.076
05/20/2025 18:12:00 - INFO - __main__ -   epoch 1 step 600 loss 0.06539
05/20/2025 18:18:44 - INFO - __main__ -   epoch 1 step 700 loss 0.06599
05/20/2025 18:24:12 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 18:24:12 - INFO - __main__ -     Num examples = 9604
05/20/2025 18:24:12 - INFO - __main__ -     Batch size = 64
05/20/2025 18:31:18 - INFO - __main__ -     eval_loss = 1.2537
05/20/2025 18:31:18 - INFO - __main__ -     eval_mrr = 0.3718
05/20/2025 18:32:35 - INFO - __main__ -   epoch 1 step 800 loss 0.034
05/20/2025 18:39:20 - INFO - __main__ -   epoch 1 step 900 loss 0.04892
05/20/2025 18:46:04 - INFO - __main__ -   epoch 1 step 1000 loss 0.06006
05/20/2025 18:52:49 - INFO - __main__ -   epoch 1 step 1100 loss 0.05825
05/20/2025 18:57:48 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 18:57:48 - INFO - __main__ -     Num examples = 9604
05/20/2025 18:57:48 - INFO - __main__ -     Batch size = 64
05/20/2025 19:04:54 - INFO - __main__ -     eval_loss = 1.2873
05/20/2025 19:04:54 - INFO - __main__ -     eval_mrr = 0.4016
05/20/2025 19:04:54 - INFO - __main__ -     ********************
05/20/2025 19:04:54 - INFO - __main__ -     Best mrr:0.4016
05/20/2025 19:04:54 - INFO - __main__ -     ********************
05/20/2025 19:04:56 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 19:06:41 - INFO - __main__ -   epoch 1 step 1200 loss 0.04765
05/20/2025 19:13:26 - INFO - __main__ -   epoch 1 step 1300 loss 0.07081
05/20/2025 19:20:11 - INFO - __main__ -   epoch 1 step 1400 loss 0.07551
05/20/2025 19:26:56 - INFO - __main__ -   epoch 1 step 1500 loss 0.07339
05/20/2025 19:31:27 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 19:31:27 - INFO - __main__ -     Num examples = 9604
05/20/2025 19:31:27 - INFO - __main__ -     Batch size = 64
05/20/2025 19:38:33 - INFO - __main__ -     eval_loss = 1.2445
05/20/2025 19:38:33 - INFO - __main__ -     eval_mrr = 0.3925
05/20/2025 19:40:47 - INFO - __main__ -   epoch 1 step 1600 loss 0.0676
05/20/2025 19:47:32 - INFO - __main__ -   epoch 1 step 1700 loss 0.06346
05/20/2025 19:54:17 - INFO - __main__ -   epoch 1 step 1800 loss 0.06421
05/20/2025 20:01:01 - INFO - __main__ -   epoch 1 step 1900 loss 0.06074
05/20/2025 20:05:04 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 20:05:04 - INFO - __main__ -     Num examples = 9604
05/20/2025 20:05:04 - INFO - __main__ -     Batch size = 64
05/20/2025 20:12:11 - INFO - __main__ -     eval_loss = 1.306
05/20/2025 20:12:11 - INFO - __main__ -     eval_mrr = 0.4068
05/20/2025 20:12:11 - INFO - __main__ -     ********************
05/20/2025 20:12:11 - INFO - __main__ -     Best mrr:0.4068
05/20/2025 20:12:11 - INFO - __main__ -     ********************
05/20/2025 20:12:12 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 20:14:54 - INFO - __main__ -   epoch 1 step 2000 loss 0.0531
05/20/2025 20:21:39 - INFO - __main__ -   epoch 1 step 2100 loss 0.06166
05/20/2025 20:28:24 - INFO - __main__ -   epoch 1 step 2200 loss 0.05969
05/20/2025 20:35:09 - INFO - __main__ -   epoch 1 step 2300 loss 0.05765
05/20/2025 20:38:43 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 20:38:43 - INFO - __main__ -     Num examples = 9604
05/20/2025 20:38:43 - INFO - __main__ -     Batch size = 64
05/20/2025 20:45:50 - INFO - __main__ -     eval_loss = 1.2327
05/20/2025 20:45:50 - INFO - __main__ -     eval_mrr = 0.4138
05/20/2025 20:45:50 - INFO - __main__ -     ********************
05/20/2025 20:45:50 - INFO - __main__ -     Best mrr:0.4138
05/20/2025 20:45:50 - INFO - __main__ -     ********************
05/20/2025 20:45:52 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 20:49:02 - INFO - __main__ -   epoch 1 step 2400 loss 0.08217
05/20/2025 20:55:47 - INFO - __main__ -   epoch 1 step 2500 loss 0.05582
05/20/2025 21:02:32 - INFO - __main__ -   epoch 1 step 2600 loss 0.05349
05/20/2025 21:09:17 - INFO - __main__ -   epoch 1 step 2700 loss 0.052
05/20/2025 21:12:24 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 21:12:24 - INFO - __main__ -     Num examples = 9604
05/20/2025 21:12:24 - INFO - __main__ -     Batch size = 64
05/20/2025 21:19:30 - INFO - __main__ -     eval_loss = 1.3095
05/20/2025 21:19:30 - INFO - __main__ -     eval_mrr = 0.4008
05/20/2025 21:23:09 - INFO - __main__ -   epoch 1 step 2800 loss 0.05721
05/20/2025 21:29:55 - INFO - __main__ -   epoch 1 step 2900 loss 0.06101
05/20/2025 21:36:40 - INFO - __main__ -   epoch 1 step 3000 loss 0.05858
05/20/2025 21:43:25 - INFO - __main__ -   epoch 1 step 3100 loss 0.05631
05/20/2025 21:46:03 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 21:46:03 - INFO - __main__ -     Num examples = 9604
05/20/2025 21:46:03 - INFO - __main__ -     Batch size = 64
05/20/2025 21:53:10 - INFO - __main__ -     eval_loss = 1.2171
05/20/2025 21:53:10 - INFO - __main__ -     eval_mrr = 0.4139
05/20/2025 21:53:10 - INFO - __main__ -     ********************
05/20/2025 21:53:10 - INFO - __main__ -     Best mrr:0.4139
05/20/2025 21:53:10 - INFO - __main__ -     ********************
05/20/2025 21:53:12 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 21:57:19 - INFO - __main__ -   epoch 1 step 3200 loss 0.03279
05/20/2025 22:04:04 - INFO - __main__ -   epoch 1 step 3300 loss 0.0524
05/20/2025 22:10:49 - INFO - __main__ -   epoch 1 step 3400 loss 0.05698
05/20/2025 22:17:35 - INFO - __main__ -   epoch 1 step 3500 loss 0.05444
05/20/2025 22:19:44 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 22:19:44 - INFO - __main__ -     Num examples = 9604
05/20/2025 22:19:44 - INFO - __main__ -     Batch size = 64
05/20/2025 22:26:51 - INFO - __main__ -     eval_loss = 1.1621
05/20/2025 22:26:51 - INFO - __main__ -     eval_mrr = 0.4194
05/20/2025 22:26:51 - INFO - __main__ -     ********************
05/20/2025 22:26:51 - INFO - __main__ -     Best mrr:0.4194
05/20/2025 22:26:51 - INFO - __main__ -     ********************
05/20/2025 22:26:53 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
05/20/2025 22:31:28 - INFO - __main__ -   epoch 1 step 3600 loss 0.05545
05/20/2025 22:38:14 - INFO - __main__ -   epoch 1 step 3700 loss 0.05257
05/20/2025 22:44:59 - INFO - __main__ -   epoch 1 step 3800 loss 0.04966
05/20/2025 22:51:44 - INFO - __main__ -   epoch 1 step 3900 loss 0.04663
05/20/2025 22:53:25 - INFO - __main__ -   ***** Running evaluation *****
05/20/2025 22:53:25 - INFO - __main__ -     Num examples = 9604
05/20/2025 22:53:25 - INFO - __main__ -     Batch size = 64
05/20/2025 23:00:32 - INFO - __main__ -     eval_loss = 1.1413
05/20/2025 23:00:32 - INFO - __main__ -     eval_mrr = 0.4215
05/20/2025 23:00:32 - INFO - __main__ -     ********************
05/20/2025 23:00:32 - INFO - __main__ -     Best mrr:0.4215
05/20/2025 23:00:32 - INFO - __main__ -     ********************
05/20/2025 23:00:34 - INFO - __main__ -   Saving model checkpoint to ./saved_models_distil_graph_compress/checkpoint-best-mrr/model.bin
